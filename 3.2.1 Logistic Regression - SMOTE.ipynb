{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c82799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # no partial fit\n",
    "from sklearn.linear_model import SGDClassifier # simulate the behavior of logistic regression using SGDClassifier(loss='log')\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import naive_bayes #import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,average_precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596f8420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc35e7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JYM\\AppData\\Local\\Temp/ipykernel_34920/1144886652.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cfpb_df = pd.read_csv('../../data/CFPB with Duplicate Marked.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Date received', 'Product', 'Sub-product', 'Issue',\n",
      "       'Sub-issue', 'Consumer complaint narrative', 'Company public response',\n",
      "       'Company', 'State', 'ZIP code', 'Tags', 'Consumer consent provided?',\n",
      "       'Submitted via', 'Date sent to company', 'Company response to consumer',\n",
      "       'Timely response?', 'Consumer disputed?', 'Complaint ID', 'narr_len',\n",
      "       'days_to_today', 'dupi_id', 'dupi_len'],\n",
      "      dtype='object')\n",
      "(1300361, 23)\n",
      "(1106587, 23)\n"
     ]
    }
   ],
   "source": [
    "cfpb_df = pd.read_csv('../../data/CFPB with Duplicate Marked.csv')\n",
    "print(cfpb_df.columns)\n",
    "print(cfpb_df.shape)\n",
    "cfpb_df = cfpb_df.drop_duplicates(subset='dupi_id')\n",
    "print(cfpb_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99dfa496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate y based on 'product' column\n",
    "cfpb_df['debt_collection'] = (cfpb_df['Product'] == 'Debt collection').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f676c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset train, dev, test\n",
    "train_df, dev_df, test_df = np.split(cfpb_df[['Consumer complaint narrative','debt_collection']].sample(len(cfpb_df), random_state = 42), \n",
    "                                     [int(len(cfpb_df)*0.75), int(len(cfpb_df)*0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eccfed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16678"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained vectorizer\n",
    "with open('tfidf_vectorizer_999.pkl', 'rb') as f:\n",
    "    loaded_vectorizer = pickle.load(f)\n",
    "len(loaded_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a3ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorize the text data with pre-tuned vectorizer\n",
    "X_train = loaded_vectorizer.transform(train_df['Consumer complaint narrative'])\n",
    "y_train = train_df['debt_collection']\n",
    "\n",
    "X_dev = loaded_vectorizer.transform(dev_df['Consumer complaint narrative'])\n",
    "y_dev = dev_df['debt_collection']\n",
    "\n",
    "X_test = loaded_vectorizer.transform(test_df['Consumer complaint narrative'])\n",
    "y_test = test_df['debt_collection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd8ccd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 345 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Select top 10000 features, 5000 runs faster without significant loss (almost the same)\n",
    "selector = SelectKBest(chi2, k=5000)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_dev = selector.transform(X_dev)\n",
    "X_test = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c453728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# some balancing\n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58bd0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# Shuffle your data\n",
    "X_train_res, y_train_res = shuffle(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d060940",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e83770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [14:59<00:00, 33.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle your data\n",
    "X_train_res, y_train_res = shuffle(X_train_res, y_train_res)\n",
    "\n",
    "clf = LogisticRegression(random_state=42, solver='saga', warm_start=True, n_jobs=-1)\n",
    "\n",
    "# The partial fit if you ran out of RAM\n",
    "batch_size = 50000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# partial fitting\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "    batch_y = y_train_res[start:end]\n",
    "    clf.fit(batch_X.A, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed8226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "accuracy_score 0.8475781746931136\n",
      "balanced_accuracy_score 0.8475781746931137\n",
      "average_precision_score 0.7967518856888538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85    683885\n",
      "           1       0.85      0.84      0.85    683885\n",
      "\n",
      "    accuracy                           0.85   1367770\n",
      "   macro avg       0.85      0.85      0.85   1367770\n",
      "weighted avg       0.85      0.85      0.85   1367770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define batch size and number of batches\n",
    "batch_size = 10000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# Initialize lists to hold batch predictions\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "# Iterate over each batch\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "\n",
    "    # Predict on the batch and append to list\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Handling the remaining data\n",
    "if X_train_res.shape[0] % batch_size != 0:\n",
    "    start = n_batches * batch_size\n",
    "    batch_X = X_train_res[start:]\n",
    "\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train_res, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train_res, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train_res, y_pred))\n",
    "print(classification_report(y_train_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebee53e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "accuracy_score 0.8482781887847314\n",
      "balanced_accuracy_score 0.8332868331189481\n",
      "average_precision_score 0.4769018019046243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90    136701\n",
      "           1       0.55      0.81      0.65     29287\n",
      "\n",
      "    accuracy                           0.85    165988\n",
      "   macro avg       0.75      0.83      0.78    165988\n",
      "weighted avg       0.88      0.85      0.86    165988\n",
      "\n",
      "Wall time: 6.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# development validation\n",
    "y_pred = clf.predict(X_dev.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_dev.toarray())\n",
    "\n",
    "print(\"Dev\")\n",
    "print(\"accuracy_score\",accuracy_score(y_dev, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_dev, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "385e53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "141bf7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2735/2735 [13:57<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle your data\n",
    "X_train_res, y_train_res = shuffle(X_train_res, y_train_res)\n",
    "\n",
    "clf = LogisticRegression(random_state=42, solver='saga', warm_start=True, n_jobs=-1)\n",
    "\n",
    "# The partial fit if you ran out of RAM\n",
    "batch_size = 500\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# partial fitting\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "    batch_y = y_train_res[start:end]\n",
    "    clf.fit(batch_X.A, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c62dc96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:52<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "accuracy_score 0.7957032249574124\n",
      "balanced_accuracy_score 0.7957032249574124\n",
      "average_precision_score 0.7387588980431945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80    683885\n",
      "           1       0.81      0.78      0.79    683885\n",
      "\n",
      "    accuracy                           0.80   1367770\n",
      "   macro avg       0.80      0.80      0.80   1367770\n",
      "weighted avg       0.80      0.80      0.80   1367770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define batch size and number of batches\n",
    "batch_size = 10000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# Initialize lists to hold batch predictions\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "# Iterate over each batch\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "\n",
    "    # Predict on the batch and append to list\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Handling the remaining data\n",
    "if X_train_res.shape[0] % batch_size != 0:\n",
    "    start = n_batches * batch_size\n",
    "    batch_X = X_train_res[start:]\n",
    "\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train_res, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train_res, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train_res, y_pred))\n",
    "print(classification_report(y_train_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4590a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "accuracy_score 0.8030821505169048\n",
      "balanced_accuracy_score 0.7814995166453249\n",
      "average_precision_score 0.39158467792845797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87    136701\n",
      "           1       0.46      0.75      0.57     29287\n",
      "\n",
      "    accuracy                           0.80    165988\n",
      "   macro avg       0.70      0.78      0.72    165988\n",
      "weighted avg       0.85      0.80      0.82    165988\n",
      "\n",
      "Wall time: 6.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# development validation\n",
    "y_pred = clf.predict(X_dev.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_dev.toarray())\n",
    "\n",
    "print(\"Dev\")\n",
    "print(\"accuracy_score\",accuracy_score(y_dev, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_dev, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3c37f",
   "metadata": {},
   "source": [
    "### The other approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "727ec4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:34<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a LogisticRegression model, ‘log_loss’ gives logistic regression, a probabilistic classifier.\n",
    "clf= SGDClassifier(loss='log_loss',random_state=42, alpha=1e-4, n_iter_no_change=3, early_stopping=False)\n",
    "\n",
    "# The partial fit if you ran out of RAM\n",
    "batch_size = 50000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# partial fitting\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "    batch_y = y_train_res[start:end]\n",
    "    if i == 0:\n",
    "        clf.partial_fit(batch_X.A, batch_y, classes=np.unique(y_train_res)) \n",
    "        # The `.A` here converts the sparse matrix to a dense matrix.\n",
    "        # This is necessary because GaussianNB doesn't support sparse matrices.\n",
    "        # We also specify the classes parameter in the first call to partial_fit.\n",
    "    else:\n",
    "        clf.partial_fit(batch_X.A, batch_y)\n",
    "\n",
    "# # if you have enough RAM resources, just go big! For 17k features you need about 60+ GB of RAM\n",
    "# gnb.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07740260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "accuracy_score 0.8443122747245516\n",
      "balanced_accuracy_score 0.8443122747245517\n",
      "average_precision_score 0.7955338728626946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85    683885\n",
      "           1       0.86      0.82      0.84    683885\n",
      "\n",
      "    accuracy                           0.84   1367770\n",
      "   macro avg       0.84      0.84      0.84   1367770\n",
      "weighted avg       0.84      0.84      0.84   1367770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the results\n",
    "# again, if you have 117 GB of memorymyou can run this.\n",
    "# y_pred = gnb.predict(X_train_res.toarray())\n",
    "# y_pred_proba = gnb.predict_proba(X_train_res.toarray())\n",
    "\n",
    "# Define batch size and number of batches\n",
    "batch_size = 10000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# Initialize lists to hold batch predictions\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "# Iterate over each batch\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "\n",
    "    # Predict on the batch and append to list\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Handling the remaining data\n",
    "if X_train_res.shape[0] % batch_size != 0:\n",
    "    start = n_batches * batch_size\n",
    "    batch_X = X_train_res[start:]\n",
    "\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train_res, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train_res, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train_res, y_pred))\n",
    "print(classification_report(y_train_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f9a9606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "accuracy_score 0.8521519627924911\n",
      "balanced_accuracy_score 0.8307154484322239\n",
      "average_precision_score 0.47960197434226476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.91    136701\n",
      "           1       0.56      0.80      0.66     29287\n",
      "\n",
      "    accuracy                           0.85    165988\n",
      "   macro avg       0.75      0.83      0.78    165988\n",
      "weighted avg       0.88      0.85      0.86    165988\n",
      "\n",
      "Wall time: 6.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# development validation\n",
    "y_pred = clf.predict(X_dev.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_dev.toarray())\n",
    "\n",
    "\n",
    "# # Initialize lists to hold batch predictions\n",
    "# y_pred = []\n",
    "# y_pred_proba = []\n",
    "\n",
    "# # Define batch size and number of batches\n",
    "# batch_size = 100\n",
    "# n_batches = X_dev.shape[0] // batch_size\n",
    "\n",
    "# # Iterate over each batch\n",
    "# for i in tqdm(range(n_batches)):\n",
    "#     start = i * batch_size\n",
    "#     end = (i + 1) * batch_size\n",
    "#     batch_X = X_dev[start:end]\n",
    "\n",
    "#     # Predict on the batch and append to list\n",
    "#     batch_pred = clf.predict(batch_X.A)\n",
    "#     batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "#     y_pred.extend(batch_pred)\n",
    "#     y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# # Convert lists to arrays for further use\n",
    "# y_pred = np.array(y_pred)\n",
    "# y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Dev\")\n",
    "print(\"accuracy_score\",accuracy_score(y_dev, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_dev, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb2e99d",
   "metadata": {},
   "source": [
    "smaller batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2f860a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2735/2735 [00:34<00:00, 78.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle your data\n",
    "X_train_res, y_train_res = shuffle(X_train_res, y_train_res)\n",
    "\n",
    "# Initialize a LogisticRegression model, ‘log_loss’ gives logistic regression, a probabilistic classifier.\n",
    "clf= SGDClassifier(loss='log_loss',random_state=42, alpha=1e-4, n_iter_no_change=3, early_stopping=False)\n",
    "\n",
    "# The partial fit if you ran out of RAM\n",
    "batch_size = 500\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# partial fitting\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "    batch_y = y_train_res[start:end]\n",
    "    if i == 0:\n",
    "        clf.partial_fit(batch_X.A, batch_y, classes=np.unique(y_train_res)) \n",
    "        # The `.A` here converts the sparse matrix to a dense matrix.\n",
    "        # This is necessary because GaussianNB doesn't support sparse matrices.\n",
    "        # We also specify the classes parameter in the first call to partial_fit.\n",
    "    else:\n",
    "        clf.partial_fit(batch_X.A, batch_y)\n",
    "\n",
    "# # if you have enough RAM resources, just go big! For 17k features you need about 60+ GB of RAM\n",
    "# gnb.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e104dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "accuracy_score 0.8456070830622108\n",
      "balanced_accuracy_score 0.8456070830622108\n",
      "average_precision_score 0.7940641757869039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85    683885\n",
      "           1       0.85      0.84      0.84    683885\n",
      "\n",
      "    accuracy                           0.85   1367770\n",
      "   macro avg       0.85      0.85      0.85   1367770\n",
      "weighted avg       0.85      0.85      0.85   1367770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the results\n",
    "# again, if you have 117 GB of memorymyou can run this.\n",
    "# y_pred = gnb.predict(X_train_res.toarray())\n",
    "# y_pred_proba = gnb.predict_proba(X_train_res.toarray())\n",
    "\n",
    "# Define batch size and number of batches\n",
    "batch_size = 10000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# Initialize lists to hold batch predictions\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "# Iterate over each batch\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "\n",
    "    # Predict on the batch and append to list\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Handling the remaining data\n",
    "if X_train_res.shape[0] % batch_size != 0:\n",
    "    start = n_batches * batch_size\n",
    "    batch_X = X_train_res[start:]\n",
    "\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train_res, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train_res, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train_res, y_pred))\n",
    "print(classification_report(y_train_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6eccfe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "accuracy_score 0.845663541942791\n",
      "balanced_accuracy_score 0.8318604046701673\n",
      "average_precision_score 0.4726377320875781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90    136701\n",
      "           1       0.54      0.81      0.65     29287\n",
      "\n",
      "    accuracy                           0.85    165988\n",
      "   macro avg       0.75      0.83      0.78    165988\n",
      "weighted avg       0.88      0.85      0.86    165988\n",
      "\n",
      "Wall time: 6.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# development validation\n",
    "y_pred = clf.predict(X_dev.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_dev.toarray())\n",
    "\n",
    "\n",
    "# # Initialize lists to hold batch predictions\n",
    "# y_pred = []\n",
    "# y_pred_proba = []\n",
    "\n",
    "# # Define batch size and number of batches\n",
    "# batch_size = 100\n",
    "# n_batches = X_dev.shape[0] // batch_size\n",
    "\n",
    "# # Iterate over each batch\n",
    "# for i in tqdm(range(n_batches)):\n",
    "#     start = i * batch_size\n",
    "#     end = (i + 1) * batch_size\n",
    "#     batch_X = X_dev[start:end]\n",
    "\n",
    "#     # Predict on the batch and append to list\n",
    "#     batch_pred = clf.predict(batch_X.A)\n",
    "#     batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "#     y_pred.extend(batch_pred)\n",
    "#     y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# # Convert lists to arrays for further use\n",
    "# y_pred = np.array(y_pred)\n",
    "# y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Dev\")\n",
    "print(\"accuracy_score\",accuracy_score(y_dev, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_dev, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
