{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c82799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # no partial fit\n",
    "from sklearn.linear_model import SGDClassifier # simulate the behavior of logistic regression using SGDClassifier(loss='log')\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn import naive_bayes #import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,average_precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "596f8420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc35e7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JYM\\AppData\\Local\\Temp/ipykernel_26128/1144886652.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cfpb_df = pd.read_csv('../../data/CFPB with Duplicate Marked.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Date received', 'Product', 'Sub-product', 'Issue',\n",
      "       'Sub-issue', 'Consumer complaint narrative', 'Company public response',\n",
      "       'Company', 'State', 'ZIP code', 'Tags', 'Consumer consent provided?',\n",
      "       'Submitted via', 'Date sent to company', 'Company response to consumer',\n",
      "       'Timely response?', 'Consumer disputed?', 'Complaint ID', 'narr_len',\n",
      "       'days_to_today', 'dupi_id', 'dupi_len'],\n",
      "      dtype='object')\n",
      "(1300361, 23)\n",
      "(1106587, 23)\n"
     ]
    }
   ],
   "source": [
    "cfpb_df = pd.read_csv('../../data/CFPB with Duplicate Marked.csv')\n",
    "print(cfpb_df.columns)\n",
    "print(cfpb_df.shape)\n",
    "cfpb_df = cfpb_df.drop_duplicates(subset='dupi_id')\n",
    "print(cfpb_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99dfa496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate y based on 'product' column\n",
    "cfpb_df['debt_collection'] = (cfpb_df['Product'] == 'Debt collection').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5f676c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset train, dev, test\n",
    "train_df, dev_df, test_df = np.split(cfpb_df[['Consumer complaint narrative','debt_collection']].sample(len(cfpb_df), random_state = 42), \n",
    "                                     [int(len(cfpb_df)*0.75), int(len(cfpb_df)*0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eccfed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16678"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained vectorizer\n",
    "with open('tfidf_vectorizer_999.pkl', 'rb') as f:\n",
    "    loaded_vectorizer = pickle.load(f)\n",
    "len(loaded_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0a3ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorize the text data with pre-tuned vectorizer\n",
    "X_train = loaded_vectorizer.transform(train_df['Consumer complaint narrative'])\n",
    "y_train = train_df['debt_collection']\n",
    "\n",
    "X_dev = loaded_vectorizer.transform(dev_df['Consumer complaint narrative'])\n",
    "y_dev = dev_df['debt_collection']\n",
    "\n",
    "X_test = loaded_vectorizer.transform(test_df['Consumer complaint narrative'])\n",
    "y_test = test_df['debt_collection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd8ccd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 351 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Select top 10000 features, 5000 runs faster without significant loss (almost the same)\n",
    "selector = SelectKBest(chi2, k=5000)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_dev = selector.transform(X_dev)\n",
    "X_test = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c453728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 322 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# some balancing\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "# fit and apply the transform\n",
    "X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d060940",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbdd69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [15:22<00:00, 34.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# Shuffle your data\n",
    "X_train_res, y_train_res = shuffle(X_train_res, y_train_res)\n",
    "\n",
    "clf = LogisticRegression(random_state=42, solver='saga', warm_start=True, n_jobs=-1)\n",
    "\n",
    "# The partial fit if you ran out of RAM\n",
    "batch_size = 50000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# partial fitting\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "    batch_y = y_train_res[start:end]\n",
    "    clf.fit(batch_X.A, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "210ed3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "accuracy_score 0.8395388113498614\n",
      "balanced_accuracy_score 0.8395388113498614\n",
      "average_precision_score 0.7942808756116194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85    683885\n",
      "           1       0.87      0.80      0.83    683885\n",
      "\n",
      "    accuracy                           0.84   1367770\n",
      "   macro avg       0.84      0.84      0.84   1367770\n",
      "weighted avg       0.84      0.84      0.84   1367770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define batch size and number of batches\n",
    "batch_size = 10000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# Initialize lists to hold batch predictions\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "# Iterate over each batch\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "\n",
    "    # Predict on the batch and append to list\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Handling the remaining data\n",
    "if X_train_res.shape[0] % batch_size != 0:\n",
    "    start = n_batches * batch_size\n",
    "    batch_X = X_train_res[start:]\n",
    "\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train_res, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train_res, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train_res, y_pred))\n",
    "print(classification_report(y_train_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c97c9ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "accuracy_score 0.8644962286430344\n",
      "balanced_accuracy_score 0.8416575116383973\n",
      "average_precision_score 0.5050978394438704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91    136701\n",
      "           1       0.58      0.81      0.68     29287\n",
      "\n",
      "    accuracy                           0.86    165988\n",
      "   macro avg       0.77      0.84      0.80    165988\n",
      "weighted avg       0.89      0.86      0.87    165988\n",
      "\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# development validation\n",
    "y_pred = clf.predict(X_dev.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_dev.toarray())\n",
    "\n",
    "print(\"Dev\")\n",
    "print(\"accuracy_score\",accuracy_score(y_dev, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_dev, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea18aa",
   "metadata": {},
   "source": [
    "Smaller batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca6083a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2735/2735 [14:02<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle your data\n",
    "X_train_res, y_train_res = shuffle(X_train_res, y_train_res)\n",
    "\n",
    "clf = LogisticRegression(random_state=42, solver='saga', warm_start=True, n_jobs=-1)\n",
    "\n",
    "# The partial fit if you ran out of RAM\n",
    "batch_size = 500\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# partial fitting\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "    batch_y = y_train_res[start:end]\n",
    "    clf.fit(batch_X.A, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d543df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:52<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "accuracy_score 0.7839095754403153\n",
      "balanced_accuracy_score 0.7839095754403153\n",
      "average_precision_score 0.7457954015070765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81    683885\n",
      "           1       0.87      0.67      0.76    683885\n",
      "\n",
      "    accuracy                           0.78   1367770\n",
      "   macro avg       0.80      0.78      0.78   1367770\n",
      "weighted avg       0.80      0.78      0.78   1367770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define batch size and number of batches\n",
    "batch_size = 10000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# Initialize lists to hold batch predictions\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "# Iterate over each batch\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "\n",
    "    # Predict on the batch and append to list\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Handling the remaining data\n",
    "if X_train_res.shape[0] % batch_size != 0:\n",
    "    start = n_batches * batch_size\n",
    "    batch_X = X_train_res[start:]\n",
    "\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train_res, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train_res, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train_res, y_pred))\n",
    "print(classification_report(y_train_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37779dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "accuracy_score 0.8577427283900041\n",
      "balanced_accuracy_score 0.7863664320546246\n",
      "average_precision_score 0.4517236199742716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91    136701\n",
      "           1       0.58      0.68      0.63     29287\n",
      "\n",
      "    accuracy                           0.86    165988\n",
      "   macro avg       0.76      0.79      0.77    165988\n",
      "weighted avg       0.87      0.86      0.86    165988\n",
      "\n",
      "Wall time: 6.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# development validation\n",
    "y_pred = clf.predict(X_dev.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_dev.toarray())\n",
    "\n",
    "print(\"Dev\")\n",
    "print(\"accuracy_score\",accuracy_score(y_dev, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_dev, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414b8cd",
   "metadata": {},
   "source": [
    "### The other approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25390684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:33<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle your data\n",
    "X_train_res, y_train_res = shuffle(X_train_res, y_train_res)\n",
    "\n",
    "# Initialize a LogisticRegression model, ‘log_loss’ gives logistic regression, a probabilistic classifier.\n",
    "clf= SGDClassifier(loss='log_loss',random_state=42, alpha=1e-4, n_iter_no_change=3, early_stopping=False)\n",
    "\n",
    "# The partial fit if you ran out of RAM\n",
    "batch_size = 50000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# partial fitting\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "    batch_y = y_train_res[start:end]\n",
    "    if i == 0:\n",
    "        clf.partial_fit(batch_X.A, batch_y, classes=np.unique(y_train_res)) \n",
    "        # The `.A` here converts the sparse matrix to a dense matrix.\n",
    "        # This is necessary because GaussianNB doesn't support sparse matrices.\n",
    "        # We also specify the classes parameter in the first call to partial_fit.\n",
    "    else:\n",
    "        clf.partial_fit(batch_X.A, batch_y)\n",
    "\n",
    "# # if you have enough RAM resources, just go big! For 17k features you need about 60+ GB of RAM\n",
    "# gnb.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8508cc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:52<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "accuracy_score 0.8369820949428632\n",
      "balanced_accuracy_score 0.8369820949428632\n",
      "average_precision_score 0.7919492211497267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84    683885\n",
      "           1       0.87      0.80      0.83    683885\n",
      "\n",
      "    accuracy                           0.84   1367770\n",
      "   macro avg       0.84      0.84      0.84   1367770\n",
      "weighted avg       0.84      0.84      0.84   1367770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the results\n",
    "# again, if you have 117 GB of memorymyou can run this.\n",
    "# y_pred = gnb.predict(X_train_res.toarray())\n",
    "# y_pred_proba = gnb.predict_proba(X_train_res.toarray())\n",
    "\n",
    "# Define batch size and number of batches\n",
    "batch_size = 10000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# Initialize lists to hold batch predictions\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "# Iterate over each batch\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "\n",
    "    # Predict on the batch and append to list\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Handling the remaining data\n",
    "if X_train_res.shape[0] % batch_size != 0:\n",
    "    start = n_batches * batch_size\n",
    "    batch_X = X_train_res[start:]\n",
    "\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train_res, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train_res, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train_res, y_pred))\n",
    "print(classification_report(y_train_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06e3a2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "accuracy_score 0.8640684868785695\n",
      "balanced_accuracy_score 0.8396270667195209\n",
      "average_precision_score 0.5028765957056941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91    136701\n",
      "           1       0.58      0.80      0.68     29287\n",
      "\n",
      "    accuracy                           0.86    165988\n",
      "   macro avg       0.77      0.84      0.79    165988\n",
      "weighted avg       0.89      0.86      0.87    165988\n",
      "\n",
      "Wall time: 6.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# development validation\n",
    "y_pred = clf.predict(X_dev.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_dev.toarray())\n",
    "\n",
    "\n",
    "# # Initialize lists to hold batch predictions\n",
    "# y_pred = []\n",
    "# y_pred_proba = []\n",
    "\n",
    "# # Define batch size and number of batches\n",
    "# batch_size = 100\n",
    "# n_batches = X_dev.shape[0] // batch_size\n",
    "\n",
    "# # Iterate over each batch\n",
    "# for i in tqdm(range(n_batches)):\n",
    "#     start = i * batch_size\n",
    "#     end = (i + 1) * batch_size\n",
    "#     batch_X = X_dev[start:end]\n",
    "\n",
    "#     # Predict on the batch and append to list\n",
    "#     batch_pred = clf.predict(batch_X.A)\n",
    "#     batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "#     y_pred.extend(batch_pred)\n",
    "#     y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# # Convert lists to arrays for further use\n",
    "# y_pred = np.array(y_pred)\n",
    "# y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Dev\")\n",
    "print(\"accuracy_score\",accuracy_score(y_dev, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_dev, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdadbbe",
   "metadata": {},
   "source": [
    "Smaller batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a52a024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2735/2735 [00:35<00:00, 76.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle your data\n",
    "X_train_res, y_train_res = shuffle(X_train_res, y_train_res)\n",
    "\n",
    "# Initialize a LogisticRegression model, ‘log_loss’ gives logistic regression, a probabilistic classifier.\n",
    "clf= SGDClassifier(loss='log_loss',random_state=42, alpha=1e-4, n_iter_no_change=3, early_stopping=False)\n",
    "\n",
    "# The partial fit if you ran out of RAM\n",
    "batch_size = 500\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# partial fitting\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "    batch_y = y_train_res[start:end]\n",
    "    if i == 0:\n",
    "        clf.partial_fit(batch_X.A, batch_y, classes=np.unique(y_train_res)) \n",
    "        # The `.A` here converts the sparse matrix to a dense matrix.\n",
    "        # This is necessary because GaussianNB doesn't support sparse matrices.\n",
    "        # We also specify the classes parameter in the first call to partial_fit.\n",
    "    else:\n",
    "        clf.partial_fit(batch_X.A, batch_y)\n",
    "\n",
    "# # if you have enough RAM resources, just go big! For 17k features you need about 60+ GB of RAM\n",
    "# gnb.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3e88a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [00:52<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "accuracy_score 0.8351893958779619\n",
      "balanced_accuracy_score 0.8351893958779619\n",
      "average_precision_score 0.7950650274596656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84    683885\n",
      "           1       0.88      0.78      0.82    683885\n",
      "\n",
      "    accuracy                           0.84   1367770\n",
      "   macro avg       0.84      0.84      0.83   1367770\n",
      "weighted avg       0.84      0.84      0.83   1367770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the results\n",
    "# again, if you have 117 GB of memorymyou can run this.\n",
    "# y_pred = gnb.predict(X_train_res.toarray())\n",
    "# y_pred_proba = gnb.predict_proba(X_train_res.toarray())\n",
    "\n",
    "# Define batch size and number of batches\n",
    "batch_size = 10000\n",
    "n_batches = X_train_res.shape[0] // batch_size\n",
    "\n",
    "# Initialize lists to hold batch predictions\n",
    "y_pred = []\n",
    "y_pred_proba = []\n",
    "\n",
    "# Iterate over each batch\n",
    "for i in tqdm(range(n_batches)):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    batch_X = X_train_res[start:end]\n",
    "\n",
    "    # Predict on the batch and append to list\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Handling the remaining data\n",
    "if X_train_res.shape[0] % batch_size != 0:\n",
    "    start = n_batches * batch_size\n",
    "    batch_X = X_train_res[start:]\n",
    "\n",
    "    batch_pred = clf.predict(batch_X.A)\n",
    "    batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "    y_pred.extend(batch_pred)\n",
    "    y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train_res, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train_res, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train_res, y_pred))\n",
    "print(classification_report(y_train_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a007ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev\n",
      "accuracy_score 0.8751114538400366\n",
      "balanced_accuracy_score 0.8384838199592077\n",
      "average_precision_score 0.5192541040789179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92    136701\n",
      "           1       0.61      0.78      0.69     29287\n",
      "\n",
      "    accuracy                           0.88    165988\n",
      "   macro avg       0.78      0.84      0.81    165988\n",
      "weighted avg       0.89      0.88      0.88    165988\n",
      "\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# development validation\n",
    "y_pred = clf.predict(X_dev.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_dev.toarray())\n",
    "\n",
    "\n",
    "# # Initialize lists to hold batch predictions\n",
    "# y_pred = []\n",
    "# y_pred_proba = []\n",
    "\n",
    "# # Define batch size and number of batches\n",
    "# batch_size = 100\n",
    "# n_batches = X_dev.shape[0] // batch_size\n",
    "\n",
    "# # Iterate over each batch\n",
    "# for i in tqdm(range(n_batches)):\n",
    "#     start = i * batch_size\n",
    "#     end = (i + 1) * batch_size\n",
    "#     batch_X = X_dev[start:end]\n",
    "\n",
    "#     # Predict on the batch and append to list\n",
    "#     batch_pred = clf.predict(batch_X.A)\n",
    "#     batch_pred_proba = clf.predict_proba(batch_X.A)\n",
    "\n",
    "#     y_pred.extend(batch_pred)\n",
    "#     y_pred_proba.extend(batch_pred_proba)\n",
    "\n",
    "# # Convert lists to arrays for further use\n",
    "# y_pred = np.array(y_pred)\n",
    "# y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Dev\")\n",
    "print(\"accuracy_score\",accuracy_score(y_dev, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_dev, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_dev, y_pred))\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
