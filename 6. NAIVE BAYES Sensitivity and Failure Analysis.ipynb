{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn import naive_bayes #import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier # simulate the behavior of logistic regression using SGDClassifier(loss='log')\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,average_precision_score, classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained vectorizer\n",
    "with open('tfidf_vectorizer_train_split_33k.pkl', 'rb') as f:\n",
    "    loaded_vectorizer = pickle.load(f)\n",
    "len(loaded_vectorizer.get_feature_names_out())\n",
    "\n",
    "train_df = pd.read_csv('cfpb_train.csv')\n",
    "test_df = pd.read_csv('cfpb_test.csv')\n",
    "dev_df = pd.read_csv('cfpb_dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f676c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some cleaning just ot make sure\n",
    "train_df['Consumer complaint narrative'] = train_df['Consumer complaint narrative'].fillna('').astype(str)\n",
    "test_df['Consumer complaint narrative'] = test_df['Consumer complaint narrative'].fillna('').astype(str)\n",
    "dev_df['Consumer complaint narrative'] = dev_df['Consumer complaint narrative'].fillna('').astype(str)\n",
    "\n",
    "train_df['debt_collection'] = (train_df['Product'] == 'Debt collection').astype(int)\n",
    "test_df['debt_collection'] = (test_df['Product'] == 'Debt collection').astype(int)\n",
    "dev_df['debt_collection'] = (dev_df['Product'] == 'Debt collection').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test = loaded_vectorizer.transform(test_df['Consumer complaint narrative'])\n",
    "y_test = test_df['debt_collection']\n",
    "\n",
    "X_dev = loaded_vectorizer.transform(dev_df['Consumer complaint narrative'])\n",
    "y_dev = dev_df['debt_collection']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c2c168",
   "metadata": {},
   "source": [
    "### Grid Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the parameters for exploration\n",
    "# First Run\n",
    "param_grid = {\n",
    "    'sample_size': [1000, 5000, 10000, 25000 ,50000, 100000, 150000, 200000, 250000,  300000], \n",
    "    'chi2_features': [500, 1000, 5000, 10000, 15000, 20000, 25000, 30000], \n",
    "    'clf__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5],\n",
    "    'clf__fit_prior': [True], \n",
    "    'clf__class_prior': [None]\n",
    "}\n",
    "\n",
    "\n",
    "def grid_search_model(param_grid, train_df, X_dev, y_dev):\n",
    "    results = []\n",
    "    best_params = None\n",
    "    best_score = 0\n",
    "    prev_score = 0\n",
    "    \n",
    "    for sample_size in param_grid['sample_size']:\n",
    "        for chi2_features in param_grid['chi2_features']:\n",
    "            \n",
    "            # Sample and transform the train data\n",
    "            train_df_sample = train_df.sample(sample_size)\n",
    "            \n",
    "            X_train = loaded_vectorizer.transform(train_df_sample['Consumer complaint narrative'])\n",
    "            y_train = train_df_sample['debt_collection']\n",
    "            \n",
    "            selector = SelectKBest(chi2, k=chi2_features)\n",
    "            X_train = selector.fit_transform(X_train, y_train)\n",
    "            # Transform dev set with the same selector\n",
    "            X_dev_transformed = selector.transform(X_dev)\n",
    "            \n",
    "            sm = SMOTE(random_state=42)\n",
    "            X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "#             oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "#             X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "            \n",
    "            # Shuffle your data\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "            \n",
    "            for params in product(\n",
    "                param_grid['clf__alpha'],\n",
    "                param_grid['clf__fit_prior'],\n",
    "                param_grid['clf__class_prior']\n",
    "            ):\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Apply the parameters\n",
    "                alpha, fit_prior, class_prior = params\n",
    "                \n",
    "                clf = naive_bayes.MultinomialNB(\n",
    "                    alpha=alpha, \n",
    "                    fit_prior=fit_prior, \n",
    "                    class_prior=class_prior\n",
    "                )\n",
    "                # Train and score the model\n",
    "                clf.fit(X_train, y_train)\n",
    "                predicted = clf.predict(X_dev_transformed)\n",
    "                score = f1_score(y_dev, predicted)\n",
    "                # Calculate training time\n",
    "                training_time = time.time() - start_time\n",
    "                \n",
    "                results.append({\n",
    "                    'sample_size': sample_size,\n",
    "                    'chi2_features': chi2_features,\n",
    "                    'clf__alpha': alpha,\n",
    "                    'clf__fit_prior': fit_prior,\n",
    "                    'clf__class_prior': class_prior,\n",
    "                    'f1_score': score,\n",
    "                    'training_time': training_time\n",
    "                })\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {\n",
    "                        'sample_size': sample_size,\n",
    "                        'chi2_features': chi2_features,\n",
    "                        'clf__alpha': alpha,\n",
    "                        'clf__fit_prior': fit_prior,\n",
    "                        'clf__class_prior': class_prior,\n",
    "                        'training_time': training_time\n",
    "                    }\n",
    "                    print(f\"New best score:{score} using {best_params}\")\n",
    "#                 else:\n",
    "#                     print(f\"Current score:{score} using sample size={sample_size}, feature size={chi2_features} with params={params}\")\n",
    "                prev_score = score\n",
    "                \n",
    "                \n",
    "                    \n",
    "    return pd.DataFrame(results), best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0666469",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df, best_params = grid_search_model(param_grid, train_df, X_dev, y_dev)\n",
    "print(f'Best parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645dbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"nb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa58c1",
   "metadata": {},
   "source": [
    "### sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "df = pd.read_csv(\"nb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# F1 Score versus Sample Size\n",
    "chart1 = alt.Chart(df).mark_circle(size=60).encode(\n",
    "    alt.X('sample_size', scale=alt.Scale(type='log'), title=\"Sample Size (log scale)\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Sample Size'\n",
    ")\n",
    "\n",
    "# F1 Score versus Chi2 Features\n",
    "chart2 = alt.Chart(df).mark_circle(size=60).encode(\n",
    "    alt.X('chi2_features', scale=alt.Scale(type='log'), title=\"Chi2 Features (log scale)\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Chi2 Features'\n",
    ")\n",
    "\n",
    "# F1 Score versus Alpha\n",
    "chart3 = alt.Chart(df).mark_circle(size=60).encode(\n",
    "    alt.X('clf__alpha', scale=alt.Scale(type='log'), title=\"Alpha (log scale)\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Alpha'\n",
    ")\n",
    "\n",
    "# Training Time versus Sample Size\n",
    "chart4 = alt.Chart(df).mark_circle(size=60).encode(\n",
    "    alt.X('sample_size', scale=alt.Scale(type='log'), title=\"Sample Size (log scale)\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Sample Size'\n",
    ")\n",
    "\n",
    "# Training Time versus Chi2 Features\n",
    "chart5 = alt.Chart(df).mark_circle(size=60).encode(\n",
    "    alt.X('chi2_features', scale=alt.Scale(type='log'), title=\"Chi2 Features (log scale)\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Chi2 Features'\n",
    ")\n",
    "\n",
    "# Training Time versus Alpha\n",
    "chart6 = alt.Chart(df).mark_circle(size=60).encode(\n",
    "    alt.X('clf__alpha', scale=alt.Scale(type='log'), title=\"Alpha (log scale)\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Alpha'\n",
    ")\n",
    "\n",
    "# Bubble Chart: Adjusted F1 Score versus Sample Size and Chi2 Features\n",
    "df['f1_score_adjusted'] = (df['f1_score'] - 0.4) * 100  # Adjusting the F1 scores\n",
    "\n",
    "chart7 = alt.Chart(df).mark_point().encode(\n",
    "    alt.X('sample_size', scale=alt.Scale(type='log'), title=\"Sample Size (log scale)\"),\n",
    "    alt.Y('chi2_features', scale=alt.Scale(type='log'), title=\"Chi2 Features (log scale)\"),\n",
    "    alt.Size('f1_score_adjusted', title=\"Adjusted F1 Score\", scale=alt.Scale(range=[10, 1000])),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Adjusted F1 Score versus Sample Size and Chi2 Features'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(chart1 | chart2 | chart3) & (chart4 | chart5 | chart6)# & chart7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score versus Sample Size\n",
    "chart1 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('sample_size', scale=alt.Scale(type='log'), title=\"Sample Size (log scale)\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Sample Size'\n",
    ")\n",
    "\n",
    "# F1 Score versus Chi2 Features\n",
    "chart2 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('chi2_features', scale=alt.Scale(type='log'), title=\"Chi2 Features (log scale)\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Chi2 Features'\n",
    ")\n",
    "\n",
    "# F1 Score versus Alpha\n",
    "chart3 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('clf__alpha', scale=alt.Scale(type='log'), title=\"Alpha (log scale)\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Alpha'\n",
    ")\n",
    "\n",
    "# Training Time versus Sample Size\n",
    "chart4 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('sample_size', scale=alt.Scale(type='log'), title=\"Sample Size (log scale)\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Sample Size'\n",
    ")\n",
    "\n",
    "# Training Time versus Chi2 Features\n",
    "chart5 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('chi2_features', scale=alt.Scale(type='log'), title=\"Chi2 Features (log scale)\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Chi2 Features'\n",
    ")\n",
    "\n",
    "# Training Time versus Alpha\n",
    "chart6 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('clf__alpha', scale=alt.Scale(type='log'), title=\"Alpha (log scale)\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Alpha'\n",
    ")\n",
    "(chart1 | chart2 | chart3) & (chart4 | chart5 | chart6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056003e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score versus Sample Size\n",
    "chart1 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('sample_size', title=\"Sample Size\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Sample Size'\n",
    ")\n",
    "\n",
    "# F1 Score versus Chi2 Features\n",
    "chart2 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('chi2_features', title=\"Chi2 Features\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Chi2 Features'\n",
    ")\n",
    "\n",
    "# F1 Score versus Alpha\n",
    "chart3 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('clf__alpha', title=\"Alpha\"),\n",
    "    alt.Y('f1_score', title=\"F1 Score\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='F1 Score versus Alpha'\n",
    ")\n",
    "\n",
    "# Training Time versus Sample Size\n",
    "chart4 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('sample_size', title=\"Sample Size\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Sample Size'\n",
    ")\n",
    "\n",
    "# Training Time versus Chi2 Features\n",
    "chart5 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('chi2_features', title=\"Chi2 Features\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Chi2 Features'\n",
    ")\n",
    "\n",
    "# Training Time versus Alpha\n",
    "chart6 = alt.Chart(df).mark_boxplot().encode(\n",
    "    alt.X('clf__alpha', title=\"Alpha\"),\n",
    "    alt.Y('training_time', title=\"Training Time\"),\n",
    "    tooltip=['sample_size', 'chi2_features', 'clf__alpha', 'clf__fit_prior', 'clf__class_prior', 'f1_score', 'training_time']\n",
    ").properties(\n",
    "    title='Training Time versus Alpha'\n",
    ")\n",
    "(chart1 | chart2 | chart3) & (chart4 | chart5 | chart6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d060940",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_params = {'sample_size': 100000, 'chi2_features': 25000, 'clf__alpha': 0.001, 'clf__fit_prior': True, 'clf__class_prior': None, 'training_time': 0.0800180435180664}\n",
    "sample_size = best_params['sample_size']\n",
    "chi2_features = best_params['chi2_features']\n",
    "alpha =  best_params['clf__alpha']\n",
    "fit_prior =  best_params['clf__fit_prior']\n",
    "class_prior =  best_params['clf__class_prior']\n",
    "\n",
    "\n",
    "train_df_sample = train_df.sample(sample_size).copy()\n",
    "            \n",
    "X_train = loaded_vectorizer.transform(train_df_sample['Consumer complaint narrative'])\n",
    "y_train = train_df_sample['debt_collection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "selector = SelectKBest(chi2, k=chi2_features)\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "# Transform dev set with the same selector\n",
    "X_dev_transformed = selector.transform(X_dev)\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e83770",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = naive_bayes.MultinomialNB(\n",
    "                    alpha=alpha, \n",
    "                    fit_prior=fit_prior, \n",
    "                    class_prior=class_prior\n",
    "                )\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the results\n",
    "y_pred = clf.predict(X_train.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_train.toarray())\n",
    "\n",
    "# Convert lists to arrays for further use\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "print(\"Train\")\n",
    "print(\"accuracy_score\",accuracy_score(y_train, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y_train, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "c = Counter(y_pred)\n",
    "print(\"Prediction\", c.most_common(2))\n",
    "c = Counter(y_train)\n",
    "print(\"Ground Truth\",c.most_common(2))\n",
    "\n",
    "prediction = pd.DataFrame(y_pred_proba)\n",
    "prediction['result'] = y_pred\n",
    "\n",
    "df = prediction.copy()\n",
    "df.columns = ['neg', 'pos', 'class']\n",
    "df['true'] = y_train\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 5)) # Adjust figsize as needed\n",
    "\n",
    "# Plot Probability Density for Different True Classes\n",
    "for class_label in df['true'].unique():\n",
    "    sns.kdeplot(df[df['true'] == class_label]['pos'], label=class_label, ax=axs[0])\n",
    "\n",
    "axs[0].set_title('Probability Density for Different True Classes')\n",
    "axs[0].set_xlabel('Probability')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend(title='True Class')\n",
    "\n",
    "# Plot Probability Density for Different Predicted Classes\n",
    "for class_label in df['class'].unique():\n",
    "    sns.kdeplot(df[df['class'] == class_label]['pos'], label=class_label, ax=axs[1])\n",
    "\n",
    "axs[1].set_title('Probability Density for Different Predicted Classes')\n",
    "axs[1].set_xlabel('Probability')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend(title='Predicted Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_analysis = dev_df.sample(20000, random_state=42).copy()\n",
    "X = loaded_vectorizer.transform(failure_analysis['Consumer complaint narrative'])\n",
    "X_transformed = selector.transform(X)\n",
    "y = failure_analysis['debt_collection']\n",
    "\n",
    "y_pred = clf.predict(X_transformed.toarray())\n",
    "y_pred_proba = clf.predict_proba(X_transformed.toarray())\n",
    "prediction = pd.DataFrame(y_pred_proba)\n",
    "prediction['result'] = y_pred\n",
    "\n",
    "failure_analysis['y_pred'] = y_pred\n",
    "failure_analysis['y_pred_proba'] = y_pred_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test\")\n",
    "print(\"accuracy_score\",accuracy_score(y, y_pred))\n",
    "print(\"balanced_accuracy_score\",balanced_accuracy_score(y, y_pred))\n",
    "print(\"average_precision_score\",average_precision_score(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prediction.copy()\n",
    "df.columns = ['neg', 'pos', 'class']\n",
    "df['true'] = y\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 5)) # Adjust figsize as needed\n",
    "\n",
    "# Plot Probability Density for Different True Classes\n",
    "for class_label in df['true'].unique():\n",
    "    sns.kdeplot(df[df['true'] == class_label]['pos'], label=class_label, ax=axs[0])\n",
    "\n",
    "axs[0].set_title('Probability Density for Different True Classes')\n",
    "axs[0].set_xlabel('Probability')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend(title='True Class')\n",
    "\n",
    "# Plot Probability Density for Different Predicted Classes\n",
    "for class_label in df['class'].unique():\n",
    "    sns.kdeplot(df[df['class'] == class_label]['pos'], label=class_label, ax=axs[1])\n",
    "\n",
    "axs[1].set_title('Probability Density for Different Predicted Classes')\n",
    "axs[1].set_xlabel('Probability')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend(title='Predicted Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0aeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfpb_df = pd.read_csv('../../data/CFPB with Duplicate Marked.csv')\n",
    "cfpb_df = cfpb_df[['Consumer complaint narrative', 'Complaint ID']]\n",
    "cfpb_df.columns = ['Original Complaint', 'Complaint ID']\n",
    "failure_analysis = failure_analysis.merge(cfpb_df, on='Complaint ID', how='left')\n",
    "failure_analysis.to_csv(\"failure example.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfdb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_analysis[(failure_analysis.y_pred!=failure_analysis['debt_collection'])&(failure_analysis.y_pred==1)][['Original Complaint','debt_collection','y_pred','y_pred_proba','Product','Complaint ID']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f416045",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_analysis[(failure_analysis.y_pred!=failure_analysis['debt_collection'])&(failure_analysis.y_pred==0)][['Original Complaint','debt_collection','y_pred','y_pred_proba','Product','Complaint ID']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_analysis['narr_length'] = failure_analysis['Original Complaint'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_analysis[(failure_analysis.y_pred!=failure_analysis['debt_collection'])&(failure_analysis.y_pred==1)]['narr_length'].plot(kind='hist', bins=100, edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d770cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_analysis[(failure_analysis.y_pred!=failure_analysis['debt_collection'])&(failure_analysis.y_pred==0)]['narr_length'].plot(kind='hist', bins=100, edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Filter the data based on the conditions\n",
    "filtered_data = failure_analysis[(failure_analysis.y_pred != failure_analysis['debt_collection'])]# & (failure_analysis.y_pred == 1)]\n",
    "\n",
    "# Create a scatter plot using Altair\n",
    "scatter_plot = alt.Chart(filtered_data).mark_circle(size=60).encode(\n",
    "    x=alt.X('narr_length', scale=alt.Scale(domain=(0, 15000))),\n",
    "    y=alt.Y('y_pred_proba', scale=alt.Scale(domain=(0, 1))),\n",
    "    color=alt.Color('y_pred_proba', scale=alt.Scale(scheme='viridis')),\n",
    "    tooltip=['narr_length', 'y_pred_proba']\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Show the scatter plot\n",
    "scatter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data based on the conditions\n",
    "filtered_data = failure_analysis[(failure_analysis.y_pred == failure_analysis['debt_collection'])]# & (failure_analysis.y_pred == 1)]\n",
    "\n",
    "# Create a scatter plot using Altair\n",
    "scatter_plot = alt.Chart(filtered_data).mark_circle(size=60).encode(\n",
    "    x=alt.X('narr_length', scale=alt.Scale(domain=(0, 15000))),\n",
    "    y=alt.Y('y_pred_proba', scale=alt.Scale(domain=(0, 1))),\n",
    "    color=alt.Color('y_pred_proba', scale=alt.Scale(scheme='viridis')),\n",
    "    tooltip=['narr_length', 'y_pred_proba']\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Show the scatter plot\n",
    "scatter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data based on the conditions\n",
    "filtered_data = failure_analysis[(failure_analysis.y_pred != failure_analysis['debt_collection'])\n",
    "                                &(failure_analysis.y_pred_proba>0.5)\n",
    "                                &(failure_analysis.y_pred_proba<1.01)]# & (failure_analysis.y_pred == 1)]\n",
    "\n",
    "# Create a scatter plot using Altair\n",
    "scatter_plot = alt.Chart(filtered_data).mark_circle(size=60).encode(\n",
    "    x=alt.X('narr_length', scale=alt.Scale(domain=(0, 7000))),\n",
    "    y=alt.Y('y_pred_proba', scale=alt.Scale(domain=(0.5, 1))),\n",
    "    color=alt.Color('y_pred_proba', scale=alt.Scale(scheme='viridis')),\n",
    "    tooltip=['narr_length', 'y_pred_proba']\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Show the scatter plot\n",
    "scatter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binning narr_length and y_pred_proba into 10 bins\n",
    "filtered_data = failure_analysis[(failure_analysis.y_pred == failure_analysis['debt_collection'])&(failure_analysis['narr_length']<3000)]\n",
    "filtered_data['narr_length_bin'] = pd.cut(filtered_data['narr_length'], bins=50)\n",
    "filtered_data['y_pred_proba_bin'] = pd.cut(filtered_data['y_pred_proba'], bins=20)\n",
    "\n",
    "# Create a pivot table for the heatmap\n",
    "heatmap_data = filtered_data.pivot_table(index='narr_length_bin', \n",
    "                                         columns='y_pred_proba_bin', \n",
    "                                         aggfunc='size')\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(heatmap_data, cmap=\"viridis\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f8a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning narr_length and y_pred_proba into 10 bins\n",
    "filtered_data = failure_analysis[(failure_analysis.y_pred != failure_analysis['debt_collection'])&(failure_analysis['narr_length']<3000)]\n",
    "filtered_data['narr_length_bin'] = pd.cut(filtered_data['narr_length'], bins=50)\n",
    "filtered_data['y_pred_proba_bin'] = pd.cut(filtered_data['y_pred_proba'], bins=20)\n",
    "\n",
    "# Create a pivot table for the heatmap\n",
    "heatmap_data = filtered_data.pivot_table(index='narr_length_bin', \n",
    "                                         columns='y_pred_proba_bin', \n",
    "                                         aggfunc='size')\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(heatmap_data, cmap=\"viridis\")\n",
    "plt.title('False Positive Predictions Probability vs Complaint Narrative Length')\n",
    "plt.ylabel('Narrative Length')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the true and predicted class labels\n",
    "y_true = failure_analysis['debt_collection']\n",
    "y_pred = failure_analysis.y_pred\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899ee92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
