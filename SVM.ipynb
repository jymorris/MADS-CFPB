{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54bda6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41026713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Product', 'Issue', 'State', 'ZIP code', 'Complaint ID',\n",
      "       'Consumer complaint narrative', 'unigram_narr'],\n",
      "      dtype='object')\n",
      "(5000, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CFPB with preprocessing')\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "048c3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target\n",
    "df['y_target'] = (df['Product'] == 'Debt collection').astype(int)\n",
    "\n",
    "# vectorization\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df['unigram_narr'].values.astype('U'))\n",
    "X_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# calculate Pearson correlations\n",
    "correlations = X_df.apply(lambda x: pearsonr(x, df['y_target'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6e107c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features with correlations above the threshold\n",
    "selected_features = correlations[correlations.abs() > 0.11].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70920e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4064\n",
      "1     936\n",
      "Name: y_target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# note the imbalance\n",
    "class_counts = df['y_target'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e013ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['alleg', 'alleg debt', 'bank', 'bill', 'call', 'call from', 'call me',\n",
      "       'ceas', 'collect', 'collect agenc', 'collect debt', 'collect on',\n",
      "       'collector', 'compani', 'contact me', 'contract', 'debt', 'debt and',\n",
      "       'debt collect', 'debt collector', 'debt from', 'debt in', 'debt is',\n",
      "       'debt owe', 'debt that', 'debt they', 'debt to', 'debt wa', 'fair debt',\n",
      "       'fdcpa', 'for debt', 'garnish', 'harass', 'harass me', 'hospit', 'inc',\n",
      "       'llc', 'loan', 'medic', 'medic bill', 'midland', 'mortgag', 'my',\n",
      "       'not owe', 'of debt', 'on debt', 'owe', 'owe them', 'phone', 'recoveri',\n",
      "       'stop', 'that owe', 'the bill', 'the collect', 'the debt', 'the origin',\n",
      "       'them', 'they call', 'thi', 'thi collect', 'thi compani', 'thi debt',\n",
      "       'threaten', 'to collect', 'to stop', 'valid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9f97cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy: 0.8683886838868389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       812\n",
      "           1       0.89      0.85      0.87       814\n",
      "\n",
      "    accuracy                           0.87      1626\n",
      "   macro avg       0.87      0.87      0.87      1626\n",
      "weighted avg       0.87      0.87      0.87      1626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_selected = X_df[selected_features]\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_selected, df['y_target'])\n",
    "\n",
    "# splitting and training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict and report\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classifier accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e9df405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       794\n",
      "           1       0.79      0.64      0.71       206\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.85      0.80      0.82      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if we don't use smote\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, df['y_target'], test_size=0.2, random_state=42)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classifier accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "565bd2cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters: {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Best score: 0.847586471944658\n",
      "Classifier accuracy: 0.8542435424354243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       812\n",
      "           1       0.89      0.81      0.85       814\n",
      "\n",
      "    accuracy                           0.85      1626\n",
      "   macro avg       0.86      0.85      0.85      1626\n",
      "weighted avg       0.86      0.85      0.85      1626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# including hyper tunning\n",
    "X_selected = X_df[selected_features]\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_selected, df['y_target'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "best_clf = SVC(**grid_search.best_params_)\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classifier accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba1799a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n",
      "Best parameters: {'C': 1000, 'class_weight': None, 'degree': 2, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Best score: 0.8600429255602199\n",
      "Classifier accuracy: 0.8690036900369004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       812\n",
      "           1       0.90      0.83      0.86       814\n",
      "\n",
      "    accuracy                           0.87      1626\n",
      "   macro avg       0.87      0.87      0.87      1626\n",
      "weighted avg       0.87      0.87      0.87      1626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wider range hyper tunning\n",
    "X_selected = X_df[selected_features]\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_selected, df['y_target'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100, 1000],  # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],  # Kernel coefficient\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],  # Kernel type\n",
    "    'degree': [2, 3, 4, 5],  # Degree for 'poly' kernel\n",
    "    'class_weight': [None, 'balanced']  # Class weight\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "best_clf = SVC(**grid_search.best_params_)\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classifier accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
