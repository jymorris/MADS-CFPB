{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c82799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn import naive_bayes #import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier # simulate the behavior of logistic regression using SGDClassifier(loss='log')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score,average_precision_score, classification_report, f1_score\n",
    " \n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596f8420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b2e9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JYM\\AppData\\Local\\Temp/ipykernel_16208/2324370275.py:6: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cfpb_df = pd.read_csv('cfpb_train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the trained vectorizer\n",
    "with open('tfidf_vectorizer_train_split_33k.pkl', 'rb') as f:\n",
    "    loaded_vectorizer = pickle.load(f)\n",
    "len(loaded_vectorizer.get_feature_names_out())\n",
    "\n",
    "cfpb_df = pd.read_csv('cfpb_train.csv')\n",
    "# some cleaning just ot make sure\n",
    "cfpb_df['Consumer complaint narrative'] = cfpb_df['Consumer complaint narrative'].fillna('').astype(str)\n",
    "cfpb_df['debt_collection'] = (cfpb_df['Product'] == 'Debt collection').astype(int)\n",
    "cv_df = cfpb_df[['Consumer complaint narrative','debt_collection']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c64ad",
   "metadata": {},
   "source": [
    "## 10-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d4df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2f6fc",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710135a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8952058111380146\n",
      "balanced_accuracy_score 0.8538224574430139\n",
      "average_precision_score 0.5692808542175429\n",
      "f1_score 0.727163840383282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     67995\n",
      "           1       0.67      0.79      0.73     14605\n",
      "\n",
      "    accuracy                           0.90     82600\n",
      "   macro avg       0.81      0.85      0.83     82600\n",
      "weighted avg       0.90      0.90      0.90     82600\n",
      "\n",
      "accuracy_score 0.8950847457627119\n",
      "balanced_accuracy_score 0.8545553637004191\n",
      "average_precision_score 0.5695110813197592\n",
      "f1_score 0.7274499937099006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     67995\n",
      "           1       0.67      0.79      0.73     14605\n",
      "\n",
      "    accuracy                           0.90     82600\n",
      "   macro avg       0.81      0.85      0.83     82600\n",
      "weighted avg       0.90      0.90      0.90     82600\n",
      "\n",
      "accuracy_score 0.8946489104116223\n",
      "balanced_accuracy_score 0.8570325380118495\n",
      "average_precision_score 0.5702497362951843\n",
      "f1_score 0.7283680859033587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93     67995\n",
      "           1       0.67      0.80      0.73     14605\n",
      "\n",
      "    accuracy                           0.89     82600\n",
      "   macro avg       0.81      0.86      0.83     82600\n",
      "weighted avg       0.90      0.89      0.90     82600\n",
      "\n",
      "accuracy_score 0.8974455205811138\n",
      "balanced_accuracy_score 0.8577365816640916\n",
      "average_precision_score 0.5767736732942853\n",
      "f1_score 0.7330370930635656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     67995\n",
      "           1       0.68      0.80      0.73     14605\n",
      "\n",
      "    accuracy                           0.90     82600\n",
      "   macro avg       0.82      0.86      0.83     82600\n",
      "weighted avg       0.91      0.90      0.90     82600\n",
      "\n",
      "accuracy_score 0.8940193704600484\n",
      "balanced_accuracy_score 0.855548020817025\n",
      "average_precision_score 0.5679101159542383\n",
      "f1_score 0.7264887833531213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93     67995\n",
      "           1       0.67      0.80      0.73     14605\n",
      "\n",
      "    accuracy                           0.89     82600\n",
      "   macro avg       0.81      0.86      0.83     82600\n",
      "weighted avg       0.90      0.89      0.90     82600\n",
      "\n",
      "accuracy_score 0.8967917675544794\n",
      "balanced_accuracy_score 0.8582534601958745\n",
      "average_precision_score 0.5756811262666375\n",
      "f1_score 0.732364298496217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     67995\n",
      "           1       0.68      0.80      0.73     14605\n",
      "\n",
      "    accuracy                           0.90     82600\n",
      "   macro avg       0.82      0.86      0.83     82600\n",
      "weighted avg       0.91      0.90      0.90     82600\n",
      "\n",
      "accuracy_score 0.8954708894780808\n",
      "balanced_accuracy_score 0.8551061532812451\n",
      "average_precision_score 0.5706962235285865\n",
      "f1_score 0.7283709809350029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     67995\n",
      "           1       0.67      0.79      0.73     14604\n",
      "\n",
      "    accuracy                           0.90     82599\n",
      "   macro avg       0.81      0.86      0.83     82599\n",
      "weighted avg       0.90      0.90      0.90     82599\n",
      "\n",
      "accuracy_score 0.8962699306287001\n",
      "balanced_accuracy_score 0.8575871955272611\n",
      "average_precision_score 0.5741051409808658\n",
      "f1_score 0.7311578286790085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     67994\n",
      "           1       0.67      0.80      0.73     14605\n",
      "\n",
      "    accuracy                           0.90     82599\n",
      "   macro avg       0.81      0.86      0.83     82599\n",
      "weighted avg       0.91      0.90      0.90     82599\n",
      "\n",
      "accuracy_score 0.8969236915701159\n",
      "balanced_accuracy_score 0.8568015139020312\n",
      "average_precision_score 0.5750101972147565\n",
      "f1_score 0.7316565809379726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     67994\n",
      "           1       0.68      0.79      0.73     14605\n",
      "\n",
      "    accuracy                           0.90     82599\n",
      "   macro avg       0.82      0.86      0.83     82599\n",
      "weighted avg       0.91      0.90      0.90     82599\n",
      "\n",
      "accuracy_score 0.8953740360052785\n",
      "balanced_accuracy_score 0.8535215846672819\n",
      "average_precision_score 0.5694473555673487\n",
      "f1_score 0.7272268164888579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     67994\n",
      "           1       0.67      0.79      0.73     14605\n",
      "\n",
      "    accuracy                           0.90     82599\n",
      "   macro avg       0.81      0.85      0.83     82599\n",
      "weighted avg       0.90      0.90      0.90     82599\n",
      "\n",
      "Mean F1: 0.7293284301950287 Std F1: 0.0023296132424127144\n",
      "Wall time: 9min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_scores = []  # to store the f1_scores for each fold\n",
    "\n",
    "for train_index, val_index in skf.split(cv_df['Consumer complaint narrative'], cv_df['debt_collection']):\n",
    "    # Logistic Regression Params:\n",
    "    sample_size = 200000\n",
    "    chi2_features = 22500\n",
    "    alpha = 0.0001\n",
    "    loss = 'log_loss'\n",
    "    penalty=  'elasticnet'\n",
    "    n_iter_no_change = 3\n",
    "    early_stopping = False\n",
    "    learning_rate = 'constant'\n",
    "    eta0 =  0.01\n",
    "    \n",
    "    \n",
    "    # split the data\n",
    "    X_train_fold, X_val_fold = cv_df['Consumer complaint narrative'][train_index], cv_df['Consumer complaint narrative'][val_index]\n",
    "    y_train_fold, y_val_fold = cv_df['debt_collection'][train_index], cv_df['debt_collection'][val_index]\n",
    "    \n",
    "    # Further Sampling Since we don't need all that\n",
    "    X_train_fold_sample = X_train_fold.sample(sample_size)\n",
    "    y_train_fold_sample = y_train_fold.loc[X_train_fold_sample.index]  # Get the corresponding labels\n",
    "    \n",
    "    # Vectorize the training and validation sets\n",
    "    X_train_fold_sample = loaded_vectorizer.transform(X_train_fold_sample)\n",
    "    X_val_fold = loaded_vectorizer.transform(X_val_fold)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(chi2, k=chi2_features)\n",
    "    X_train_fold_sample = selector.fit_transform(X_train_fold_sample, y_train_fold_sample)\n",
    "    X_val_fold = selector.transform(X_val_fold)\n",
    "    \n",
    "    # Oversampling\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_train_fold_sample, y_train_fold_sample = oversample.fit_resample(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Shuffle your data\n",
    "    X_train_fold_sample, y_train_fold_sample = shuffle(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Define the classifier:\n",
    "    clf = SGDClassifier(loss=loss, \n",
    "                        penalty=penalty, \n",
    "                        alpha=alpha,\n",
    "                        n_iter_no_change=n_iter_no_change,\n",
    "                        early_stopping=early_stopping,\n",
    "                        learning_rate=learning_rate,\n",
    "                        eta0=eta0,\n",
    "                        random_state=42)\n",
    "    clf.fit(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = clf.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate the f1_score and append to the list of f1_scores\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(\"accuracy_score\",accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"balanced_accuracy_score\",balanced_accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"average_precision_score\",average_precision_score(y_val_fold, y_val_pred))\n",
    "    print(\"f1_score\",f1)\n",
    "    print(classification_report(y_val_fold, y_val_pred))\n",
    "    \n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "print('Mean F1:', mean_f1, 'Std F1:', std_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2148924",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9f993d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9158474576271186\n",
      "balanced_accuracy_score 0.8446668790893987\n",
      "average_precision_score 0.61788161387257\n",
      "f1_score 0.7553067905797867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     67995\n",
      "           1       0.78      0.73      0.76     14605\n",
      "\n",
      "    accuracy                           0.92     82600\n",
      "   macro avg       0.86      0.84      0.85     82600\n",
      "weighted avg       0.91      0.92      0.91     82600\n",
      "\n",
      "accuracy_score 0.916271186440678\n",
      "balanced_accuracy_score 0.8449511323241818\n",
      "average_precision_score 0.6193445836033826\n",
      "f1_score 0.756255727074082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     67995\n",
      "           1       0.78      0.73      0.76     14605\n",
      "\n",
      "    accuracy                           0.92     82600\n",
      "   macro avg       0.86      0.84      0.85     82600\n",
      "weighted avg       0.91      0.92      0.92     82600\n",
      "\n",
      "accuracy_score 0.917360774818402\n",
      "balanced_accuracy_score 0.8474946415371432\n",
      "average_precision_score 0.6238926046762713\n",
      "f1_score 0.7598508302842668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     67995\n",
      "           1       0.78      0.74      0.76     14605\n",
      "\n",
      "    accuracy                           0.92     82600\n",
      "   macro avg       0.86      0.85      0.85     82600\n",
      "weighted avg       0.92      0.92      0.92     82600\n",
      "\n",
      "accuracy_score 0.9184624697336562\n",
      "balanced_accuracy_score 0.8482982152336704\n",
      "average_precision_score 0.6277772444903079\n",
      "f1_score 0.7623751896411811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     67995\n",
      "           1       0.79      0.74      0.76     14605\n",
      "\n",
      "    accuracy                           0.92     82600\n",
      "   macro avg       0.87      0.85      0.86     82600\n",
      "weighted avg       0.92      0.92      0.92     82600\n",
      "\n",
      "accuracy_score 0.914769975786925\n",
      "balanced_accuracy_score 0.8430715712804768\n",
      "average_precision_score 0.6138062413956284\n",
      "f1_score 0.7523394075846056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95     67995\n",
      "           1       0.77      0.73      0.75     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.86      0.84      0.85     82600\n",
      "weighted avg       0.91      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.917227602905569\n",
      "balanced_accuracy_score 0.8474137532365327\n",
      "average_precision_score 0.6234330264874646\n",
      "f1_score 0.759556884121681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     67995\n",
      "           1       0.78      0.74      0.76     14605\n",
      "\n",
      "    accuracy                           0.92     82600\n",
      "   macro avg       0.86      0.85      0.85     82600\n",
      "weighted avg       0.92      0.92      0.92     82600\n",
      "\n",
      "accuracy_score 0.9162217460259809\n",
      "balanced_accuracy_score 0.8442136556877431\n",
      "average_precision_score 0.618855729980388\n",
      "f1_score 0.7556842253918937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     67995\n",
      "           1       0.78      0.73      0.76     14604\n",
      "\n",
      "    accuracy                           0.92     82599\n",
      "   macro avg       0.86      0.84      0.85     82599\n",
      "weighted avg       0.91      0.92      0.92     82599\n",
      "\n",
      "accuracy_score 0.9178682550636206\n",
      "balanced_accuracy_score 0.8494966851546812\n",
      "average_precision_score 0.6263599767354258\n",
      "f1_score 0.7620317103970815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     67994\n",
      "           1       0.78      0.74      0.76     14605\n",
      "\n",
      "    accuracy                           0.92     82599\n",
      "   macro avg       0.86      0.85      0.86     82599\n",
      "weighted avg       0.92      0.92      0.92     82599\n",
      "\n",
      "accuracy_score 0.9191999903146527\n",
      "balanced_accuracy_score 0.8497948360971135\n",
      "average_precision_score 0.6307890620092279\n",
      "f1_score 0.7646685472496474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95     67994\n",
      "           1       0.79      0.74      0.76     14605\n",
      "\n",
      "    accuracy                           0.92     82599\n",
      "   macro avg       0.87      0.85      0.86     82599\n",
      "weighted avg       0.92      0.92      0.92     82599\n",
      "\n",
      "accuracy_score 0.9167544401263937\n",
      "balanced_accuracy_score 0.8445729156257892\n",
      "average_precision_score 0.6207319616444162\n",
      "f1_score 0.7568943572337717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     67994\n",
      "           1       0.78      0.73      0.76     14605\n",
      "\n",
      "    accuracy                           0.92     82599\n",
      "   macro avg       0.86      0.84      0.85     82599\n",
      "weighted avg       0.91      0.92      0.92     82599\n",
      "\n",
      "Mean F1: 0.7584963669557998 Std F1: 0.0036355960224001187\n",
      "Wall time: 6min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_scores = []  # to store the f1_scores for each fold\n",
    "\n",
    "for train_index, val_index in skf.split(cv_df['Consumer complaint narrative'], cv_df['debt_collection']):\n",
    "    # Logistic Regression Params:\n",
    "    sample_size = 100000#150000\n",
    "    chi2_features = 25000#27500\n",
    "    alpha =  0.001\n",
    "    fit_prior =  True\n",
    "    class_prior =  None\n",
    "    \n",
    "    \n",
    "    # split the data\n",
    "    X_train_fold, X_val_fold = cv_df['Consumer complaint narrative'][train_index], cv_df['Consumer complaint narrative'][val_index]\n",
    "    y_train_fold, y_val_fold = cv_df['debt_collection'][train_index], cv_df['debt_collection'][val_index]\n",
    "    \n",
    "    # Further Sampling Since we don't need all that\n",
    "    X_train_fold_sample = X_train_fold.sample(sample_size)\n",
    "    y_train_fold_sample = y_train_fold.loc[X_train_fold_sample.index]  # Get the corresponding labels\n",
    "    \n",
    "    # Vectorize the training and validation sets\n",
    "    X_train_fold_sample = loaded_vectorizer.transform(X_train_fold_sample)\n",
    "    X_val_fold = loaded_vectorizer.transform(X_val_fold)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(chi2, k=chi2_features)\n",
    "    X_train_fold_sample = selector.fit_transform(X_train_fold_sample, y_train_fold_sample)\n",
    "    X_val_fold = selector.transform(X_val_fold)\n",
    "    \n",
    "    # Oversampling\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Shuffle your data\n",
    "    X_train_fold_sample, y_train_fold_sample = shuffle(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Define the classifier:\n",
    "    clf = naive_bayes.MultinomialNB(\n",
    "        alpha=alpha,\n",
    "        fit_prior=fit_prior, \n",
    "        class_prior=class_prior\n",
    "    )\n",
    "    clf.fit(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = clf.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate the f1_score and append to the list of f1_scores\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(\"accuracy_score\",accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"balanced_accuracy_score\",balanced_accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"average_precision_score\",average_precision_score(y_val_fold, y_val_pred))\n",
    "    print(\"f1_score\",f1)\n",
    "    print(classification_report(y_val_fold, y_val_pred))\n",
    "    \n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "print('Mean F1:', mean_f1, 'Std F1:', std_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8528e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.5658595641646489\n",
      "balanced_accuracy_score 0.7133205693402502\n",
      "average_precision_score 0.27586340758692496\n",
      "f1_score 0.43402777777777773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.49      0.65     67995\n",
      "           1       0.28      0.94      0.43     14605\n",
      "\n",
      "    accuracy                           0.57     82600\n",
      "   macro avg       0.63      0.71      0.54     82600\n",
      "weighted avg       0.85      0.57      0.61     82600\n",
      "\n",
      "accuracy_score 0.5761380145278451\n",
      "balanced_accuracy_score 0.7210959134956633\n",
      "average_precision_score 0.28147696405894546\n",
      "f1_score 0.44094211576846304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.50      0.66     67995\n",
      "           1       0.29      0.95      0.44     14605\n",
      "\n",
      "    accuracy                           0.58     82600\n",
      "   macro avg       0.63      0.72      0.55     82600\n",
      "weighted avg       0.86      0.58      0.62     82600\n",
      "\n",
      "accuracy_score 0.5679782082324455\n",
      "balanced_accuracy_score 0.7153601070058744\n",
      "average_precision_score 0.2772591748598922\n",
      "f1_score 0.4357299852943502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.49      0.65     67995\n",
      "           1       0.28      0.94      0.44     14605\n",
      "\n",
      "    accuracy                           0.57     82600\n",
      "   macro avg       0.63      0.72      0.54     82600\n",
      "weighted avg       0.85      0.57      0.61     82600\n",
      "\n",
      "accuracy_score 0.5702179176755447\n",
      "balanced_accuracy_score 0.7170699589521643\n",
      "average_precision_score 0.278484540861275\n",
      "f1_score 0.4372404172347104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.49      0.65     67995\n",
      "           1       0.28      0.94      0.44     14605\n",
      "\n",
      "    accuracy                           0.57     82600\n",
      "   macro avg       0.63      0.72      0.54     82600\n",
      "weighted avg       0.85      0.57      0.61     82600\n",
      "\n",
      "accuracy_score 0.5619854721549636\n",
      "balanced_accuracy_score 0.7116932521092044\n",
      "average_precision_score 0.2745511061989479\n",
      "f1_score 0.4323281137226598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.48      0.64     67995\n",
      "           1       0.28      0.94      0.43     14605\n",
      "\n",
      "    accuracy                           0.56     82600\n",
      "   macro avg       0.63      0.71      0.54     82600\n",
      "weighted avg       0.85      0.56      0.61     82600\n",
      "\n",
      "accuracy_score 0.5663075060532687\n",
      "balanced_accuracy_score 0.7126786816166151\n",
      "average_precision_score 0.27553379189479243\n",
      "f1_score 0.4336732274128527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.49      0.65     67995\n",
      "           1       0.28      0.94      0.43     14605\n",
      "\n",
      "    accuracy                           0.57     82600\n",
      "   macro avg       0.63      0.71      0.54     82600\n",
      "weighted avg       0.85      0.57      0.61     82600\n",
      "\n",
      "accuracy_score 0.5635903582367825\n",
      "balanced_accuracy_score 0.7149006724055245\n",
      "average_precision_score 0.2765487202851056\n",
      "f1_score 0.43468987689171185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.48      0.64     67995\n",
      "           1       0.28      0.95      0.43     14604\n",
      "\n",
      "    accuracy                           0.56     82599\n",
      "   macro avg       0.63      0.71      0.54     82599\n",
      "weighted avg       0.85      0.56      0.61     82599\n",
      "\n",
      "accuracy_score 0.5713749561132702\n",
      "balanced_accuracy_score 0.7185248276483143\n",
      "average_precision_score 0.27946032400680476\n",
      "f1_score 0.43840614193712124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.49      0.65     67994\n",
      "           1       0.29      0.95      0.44     14605\n",
      "\n",
      "    accuracy                           0.57     82599\n",
      "   macro avg       0.63      0.72      0.55     82599\n",
      "weighted avg       0.85      0.57      0.62     82599\n",
      "\n",
      "accuracy_score 0.5743895204542427\n",
      "balanced_accuracy_score 0.7182322519405497\n",
      "average_precision_score 0.2796005503891898\n",
      "f1_score 0.43873233814959683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.50      0.66     67994\n",
      "           1       0.29      0.94      0.44     14605\n",
      "\n",
      "    accuracy                           0.57     82599\n",
      "   macro avg       0.63      0.72      0.55     82599\n",
      "weighted avg       0.85      0.57      0.62     82599\n",
      "\n",
      "accuracy_score 0.5675008172011767\n",
      "balanced_accuracy_score 0.7140480592176623\n",
      "average_precision_score 0.27644958051619767\n",
      "f1_score 0.4347826086956522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.49      0.65     67994\n",
      "           1       0.28      0.94      0.43     14605\n",
      "\n",
      "    accuracy                           0.57     82599\n",
      "   macro avg       0.63      0.71      0.54     82599\n",
      "weighted avg       0.85      0.57      0.61     82599\n",
      "\n",
      "Mean F1: 0.4360552602884896 Std F1: 0.002554318873269745\n",
      "Wall time: 45min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_scores = []  # to store the f1_scores for each fold\n",
    "\n",
    "for train_index, val_index in skf.split(cv_df['Consumer complaint narrative'], cv_df['debt_collection']):\n",
    "    # Logistic Regression Params:\n",
    "    sample_size = 200000#150000\n",
    "    chi2_features = 25000#27500\n",
    "    \n",
    "    # split the data\n",
    "    X_train_fold, X_val_fold = cv_df['Consumer complaint narrative'][train_index], cv_df['Consumer complaint narrative'][val_index]\n",
    "    y_train_fold, y_val_fold = cv_df['debt_collection'][train_index], cv_df['debt_collection'][val_index]\n",
    "    \n",
    "    # Further Sampling Since we don't need all that\n",
    "    X_train_fold_sample = X_train_fold.sample(sample_size)\n",
    "    y_train_fold_sample = y_train_fold.loc[X_train_fold_sample.index]  # Get the corresponding labels\n",
    "    \n",
    "    # Vectorize the training and validation sets\n",
    "    X_train_fold_sample = loaded_vectorizer.transform(X_train_fold_sample)\n",
    "    X_val_fold = loaded_vectorizer.transform(X_val_fold)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(chi2, k=chi2_features)\n",
    "    X_train_fold_sample = selector.fit_transform(X_train_fold_sample, y_train_fold_sample)\n",
    "    X_val_fold = selector.transform(X_val_fold)\n",
    "    \n",
    "    # Oversampling\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Shuffle your data\n",
    "    X_train_fold_sample, y_train_fold_sample = shuffle(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Define the classifier:\n",
    "    clf = naive_bayes.GaussianNB()\n",
    "    clf.fit(X_train_fold_sample.toarray(), y_train_fold_sample)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = clf.predict(X_val_fold.toarray())\n",
    "    \n",
    "    # Calculate the f1_score and append to the list of f1_scores\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(\"accuracy_score\",accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"balanced_accuracy_score\",balanced_accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"average_precision_score\",average_precision_score(y_val_fold, y_val_pred))\n",
    "    print(\"f1_score\",f1)\n",
    "    print(classification_report(y_val_fold, y_val_pred))\n",
    "    \n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "print('Mean F1:', mean_f1, 'Std F1:', std_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f105033",
   "metadata": {},
   "source": [
    "### SVM NON-LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ca621a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9027966101694915\n",
      "balanced_accuracy_score 0.8790779821270363\n",
      "average_precision_score 0.6026798383879122\n",
      "f1_score 0.7539757928604258\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67995\n",
      "           1       0.68      0.84      0.75     14605\n",
      "\n",
      "    accuracy                           0.90     82600\n",
      "   macro avg       0.82      0.88      0.85     82600\n",
      "weighted avg       0.91      0.90      0.91     82600\n",
      "\n",
      "accuracy_score 0.9066949152542373\n",
      "balanced_accuracy_score 0.8781125135089705\n",
      "average_precision_score 0.6110415246973934\n",
      "f1_score 0.7596444721659129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67995\n",
      "           1       0.70      0.83      0.76     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.83      0.88      0.85     82600\n",
      "weighted avg       0.92      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.9065859564164649\n",
      "balanced_accuracy_score 0.8808688759386043\n",
      "average_precision_score 0.6125129334740556\n",
      "f1_score 0.7609961590880933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67995\n",
      "           1       0.69      0.84      0.76     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.83      0.88      0.85     82600\n",
      "weighted avg       0.92      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.9076029055690072\n",
      "balanced_accuracy_score 0.8825887045533862\n",
      "average_precision_score 0.6159908050820404\n",
      "f1_score 0.7635834211015428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67995\n",
      "           1       0.70      0.84      0.76     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.83      0.88      0.85     82600\n",
      "weighted avg       0.92      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.9043099273607749\n",
      "balanced_accuracy_score 0.8781692342553231\n",
      "average_precision_score 0.6055165960371418\n",
      "f1_score 0.7558534626552171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67995\n",
      "           1       0.69      0.84      0.76     14605\n",
      "\n",
      "    accuracy                           0.90     82600\n",
      "   macro avg       0.83      0.88      0.85     82600\n",
      "weighted avg       0.91      0.90      0.91     82600\n",
      "\n",
      "accuracy_score 0.9056658595641647\n",
      "balanced_accuracy_score 0.8805250622698434\n",
      "average_precision_score 0.6101480959447291\n",
      "f1_score 0.7593278972078082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67995\n",
      "           1       0.69      0.84      0.76     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.83      0.88      0.85     82600\n",
      "weighted avg       0.92      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.9076502136829744\n",
      "balanced_accuracy_score 0.8776930541257957\n",
      "average_precision_score 0.613049487560295\n",
      "f1_score 0.7609526794108429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67995\n",
      "           1       0.70      0.83      0.76     14604\n",
      "\n",
      "    accuracy                           0.91     82599\n",
      "   macro avg       0.83      0.88      0.85     82599\n",
      "weighted avg       0.92      0.91      0.91     82599\n",
      "\n",
      "accuracy_score 0.9068632792164554\n",
      "balanced_accuracy_score 0.8813868814390926\n",
      "average_precision_score 0.6134941323163089\n",
      "f1_score 0.7617307275373991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67994\n",
      "           1       0.70      0.84      0.76     14605\n",
      "\n",
      "    accuracy                           0.91     82599\n",
      "   macro avg       0.83      0.88      0.85     82599\n",
      "weighted avg       0.92      0.91      0.91     82599\n",
      "\n",
      "accuracy_score 0.9050351699173114\n",
      "balanced_accuracy_score 0.880679708261509\n",
      "average_precision_score 0.6087942354991266\n",
      "f1_score 0.7584082789207836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67994\n",
      "           1       0.69      0.84      0.76     14605\n",
      "\n",
      "    accuracy                           0.91     82599\n",
      "   macro avg       0.83      0.88      0.85     82599\n",
      "weighted avg       0.92      0.91      0.91     82599\n",
      "\n",
      "accuracy_score 0.9081102676787854\n",
      "balanced_accuracy_score 0.8797249877164082\n",
      "average_precision_score 0.6154292334475698\n",
      "f1_score 0.7628421447319086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     67994\n",
      "           1       0.70      0.84      0.76     14605\n",
      "\n",
      "    accuracy                           0.91     82599\n",
      "   macro avg       0.83      0.88      0.85     82599\n",
      "weighted avg       0.92      0.91      0.91     82599\n",
      "\n",
      "Mean F1: 0.7597315035679933 Std F1: 0.002858140667212191\n",
      "Wall time: 9min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_scores = []  # to store the f1_scores for each fold\n",
    "\n",
    "for train_index, val_index in skf.split(cv_df['Consumer complaint narrative'], cv_df['debt_collection']):\n",
    "    # SVM Params:\n",
    "    sample_size =200000\n",
    "    chi2_features = 20000\n",
    "    alpha = 0.0001\n",
    "    loss = 'squared_hinge'\n",
    "    penalty=  'elasticnet'\n",
    "    n_iter_no_change = 3\n",
    "    early_stopping = False\n",
    "    learning_rate = 'constant'\n",
    "    eta0 =  0.01\n",
    "    \n",
    "    \n",
    "    # split the data\n",
    "    X_train_fold, X_val_fold = cv_df['Consumer complaint narrative'][train_index], cv_df['Consumer complaint narrative'][val_index]\n",
    "    y_train_fold, y_val_fold = cv_df['debt_collection'][train_index], cv_df['debt_collection'][val_index]\n",
    "    \n",
    "    # Further Sampling Since we don't need all that\n",
    "    X_train_fold_sample = X_train_fold.sample(sample_size)\n",
    "    y_train_fold_sample = y_train_fold.loc[X_train_fold_sample.index]  # Get the corresponding labels\n",
    "    \n",
    "    # Vectorize the training and validation sets\n",
    "    X_train_fold_sample = loaded_vectorizer.transform(X_train_fold_sample)\n",
    "    X_val_fold = loaded_vectorizer.transform(X_val_fold)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(chi2, k=chi2_features)\n",
    "    X_train_fold_sample = selector.fit_transform(X_train_fold_sample, y_train_fold_sample)\n",
    "    X_val_fold = selector.transform(X_val_fold)\n",
    "    \n",
    "    # Oversampling\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_train_fold_sample, y_train_fold_sample = oversample.fit_resample(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Shuffle your data\n",
    "    X_train_fold_sample, y_train_fold_sample = shuffle(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Define the classifier:\n",
    "    clf = SGDClassifier(\n",
    "                    loss=loss, \n",
    "                    penalty=penalty, \n",
    "                    alpha=alpha, \n",
    "                    n_iter_no_change=n_iter_no_change, \n",
    "                    early_stopping=early_stopping, \n",
    "                    learning_rate=learning_rate, \n",
    "                    eta0=eta0, \n",
    "                    random_state=42\n",
    "                )\n",
    "    clf.fit(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = clf.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate the f1_score and append to the list of f1_scores\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(\"accuracy_score\",accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"balanced_accuracy_score\",balanced_accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"average_precision_score\",average_precision_score(y_val_fold, y_val_pred))\n",
    "    print(\"f1_score\",f1)\n",
    "    print(classification_report(y_val_fold, y_val_pred))\n",
    "    \n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "print('Mean F1:', mean_f1, 'Std F1:', std_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2760098",
   "metadata": {},
   "source": [
    "### SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "904ab90e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9050968523002422\n",
      "balanced_accuracy_score 0.8584055395659492\n",
      "average_precision_score 0.5950870126526203\n",
      "f1_score 0.7455118007986234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     67995\n",
      "           1       0.71      0.79      0.75     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.83      0.86      0.84     82600\n",
      "weighted avg       0.91      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.9059927360774819\n",
      "balanced_accuracy_score 0.8603475284232467\n",
      "average_precision_score 0.5984769687383495\n",
      "f1_score 0.7481594395615088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     67995\n",
      "           1       0.71      0.79      0.75     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.83      0.86      0.85     82600\n",
      "weighted avg       0.91      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.9045762711864407\n",
      "balanced_accuracy_score 0.8618796129032485\n",
      "average_precision_score 0.5959186032104625\n",
      "f1_score 0.7467874582369571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     67995\n",
      "           1       0.70      0.80      0.75     14605\n",
      "\n",
      "    accuracy                           0.90     82600\n",
      "   macro avg       0.83      0.86      0.84     82600\n",
      "weighted avg       0.91      0.90      0.91     82600\n",
      "\n",
      "accuracy_score 0.9067796610169492\n",
      "balanced_accuracy_score 0.8641050317880121\n",
      "average_precision_score 0.6026829605655829\n",
      "f1_score 0.7517090158648266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94     67995\n",
      "           1       0.71      0.80      0.75     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.83      0.86      0.85     82600\n",
      "weighted avg       0.91      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.903414043583535\n",
      "balanced_accuracy_score 0.857141473262667\n",
      "average_precision_score 0.5901971252420626\n",
      "f1_score 0.7420126762385203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     67995\n",
      "           1       0.70      0.79      0.74     14605\n",
      "\n",
      "    accuracy                           0.90     82600\n",
      "   macro avg       0.83      0.86      0.84     82600\n",
      "weighted avg       0.91      0.90      0.91     82600\n",
      "\n",
      "accuracy_score 0.9062590799031477\n",
      "balanced_accuracy_score 0.863224323314145\n",
      "average_precision_score 0.6008616087951493\n",
      "f1_score 0.7503305065617645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94     67995\n",
      "           1       0.71      0.80      0.75     14605\n",
      "\n",
      "    accuracy                           0.91     82600\n",
      "   macro avg       0.83      0.86      0.85     82600\n",
      "weighted avg       0.91      0.91      0.91     82600\n",
      "\n",
      "accuracy_score 0.905023063233211\n",
      "balanced_accuracy_score 0.8566066563331214\n",
      "average_precision_score 0.5938085015349989\n",
      "f1_score 0.7442709521791571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     67995\n",
      "           1       0.71      0.78      0.74     14604\n",
      "\n",
      "    accuracy                           0.91     82599\n",
      "   macro avg       0.83      0.86      0.84     82599\n",
      "weighted avg       0.91      0.91      0.91     82599\n",
      "\n",
      "accuracy_score 0.9059673845930338\n",
      "balanced_accuracy_score 0.8619989517773368\n",
      "average_precision_score 0.599406279754678\n",
      "f1_score 0.7491198036112278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     67994\n",
      "           1       0.71      0.79      0.75     14605\n",
      "\n",
      "    accuracy                           0.91     82599\n",
      "   macro avg       0.83      0.86      0.85     82599\n",
      "weighted avg       0.91      0.91      0.91     82599\n",
      "\n",
      "accuracy_score 0.9061126648022373\n",
      "balanced_accuracy_score 0.8621678386407758\n",
      "average_precision_score 0.5998680223295095\n",
      "f1_score 0.7494588569767067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     67994\n",
      "           1       0.71      0.79      0.75     14605\n",
      "\n",
      "    accuracy                           0.91     82599\n",
      "   macro avg       0.83      0.86      0.85     82599\n",
      "weighted avg       0.91      0.91      0.91     82599\n",
      "\n",
      "accuracy_score 0.9047203961307038\n",
      "balanced_accuracy_score 0.858445880855206\n",
      "average_precision_score 0.5941853731036426\n",
      "f1_score 0.7449277241200494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     67994\n",
      "           1       0.71      0.79      0.74     14605\n",
      "\n",
      "    accuracy                           0.90     82599\n",
      "   macro avg       0.83      0.86      0.84     82599\n",
      "weighted avg       0.91      0.90      0.91     82599\n",
      "\n",
      "Mean F1: 0.7472288234149342 Std F1: 0.0028896831382817178\n",
      "Wall time: 6min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_scores = []  # to store the f1_scores for each fold\n",
    "\n",
    "for train_index, val_index in skf.split(cv_df['Consumer complaint narrative'], cv_df['debt_collection']):\n",
    "    # SVM Linear\n",
    "    sample_size =100000\n",
    "    chi2_features = 20000\n",
    "    alpha = 0.0001\n",
    "    loss = 'hinge'\n",
    "    penalty=  'elasticnet'\n",
    "    n_iter_no_change = 3\n",
    "    early_stopping = False\n",
    "    learning_rate = 'adaptive'\n",
    "    eta0 =  0.01\n",
    "    \n",
    "    \n",
    "    # split the data\n",
    "    X_train_fold, X_val_fold = cv_df['Consumer complaint narrative'][train_index], cv_df['Consumer complaint narrative'][val_index]\n",
    "    y_train_fold, y_val_fold = cv_df['debt_collection'][train_index], cv_df['debt_collection'][val_index]\n",
    "    \n",
    "    # Further Sampling Since we don't need all that\n",
    "    X_train_fold_sample = X_train_fold.sample(sample_size)\n",
    "    y_train_fold_sample = y_train_fold.loc[X_train_fold_sample.index]  # Get the corresponding labels\n",
    "    \n",
    "    # Vectorize the training and validation sets\n",
    "    X_train_fold_sample = loaded_vectorizer.transform(X_train_fold_sample)\n",
    "    X_val_fold = loaded_vectorizer.transform(X_val_fold)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(chi2, k=chi2_features)\n",
    "    X_train_fold_sample = selector.fit_transform(X_train_fold_sample, y_train_fold_sample)\n",
    "    X_val_fold = selector.transform(X_val_fold)\n",
    "    \n",
    "    # Oversampling\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_train_fold_sample, y_train_fold_sample = oversample.fit_resample(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Shuffle your data\n",
    "    X_train_fold_sample, y_train_fold_sample = shuffle(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Define the classifier:\n",
    "    clf = SGDClassifier(\n",
    "                    loss=loss, \n",
    "                    penalty=penalty, \n",
    "                    alpha=alpha, \n",
    "                    n_iter_no_change=n_iter_no_change, \n",
    "                    early_stopping=early_stopping, \n",
    "                    learning_rate=learning_rate, \n",
    "                    eta0=eta0, \n",
    "                    random_state=42\n",
    "                )\n",
    "    clf.fit(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = clf.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate the f1_score and append to the list of f1_scores\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(\"accuracy_score\",accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"balanced_accuracy_score\",balanced_accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"average_precision_score\",average_precision_score(y_val_fold, y_val_pred))\n",
    "    print(\"f1_score\",f1)\n",
    "    print(classification_report(y_val_fold, y_val_pred))\n",
    "    \n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "print('Mean F1:', mean_f1, 'Std F1:', std_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b89381",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c726be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.8560532687651332\n",
      "balanced_accuracy_score 0.794127787806054\n",
      "average_precision_score 0.4561119240065308\n",
      "f1_score 0.6317517343904856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     67995\n",
      "           1       0.58      0.70      0.63     14605\n",
      "\n",
      "    accuracy                           0.86     82600\n",
      "   macro avg       0.75      0.79      0.77     82600\n",
      "weighted avg       0.87      0.86      0.86     82600\n",
      "\n",
      "accuracy_score 0.8576029055690073\n",
      "balanced_accuracy_score 0.7895583527989137\n",
      "average_precision_score 0.4547008366389653\n",
      "f1_score 0.6295433070866142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     67995\n",
      "           1       0.58      0.68      0.63     14605\n",
      "\n",
      "    accuracy                           0.86     82600\n",
      "   macro avg       0.76      0.79      0.77     82600\n",
      "weighted avg       0.87      0.86      0.86     82600\n",
      "\n",
      "accuracy_score 0.8557384987893463\n",
      "balanced_accuracy_score 0.7904689006499285\n",
      "average_precision_score 0.45276936168403636\n",
      "f1_score 0.6282755178437734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     67995\n",
      "           1       0.58      0.69      0.63     14605\n",
      "\n",
      "    accuracy                           0.86     82600\n",
      "   macro avg       0.75      0.79      0.77     82600\n",
      "weighted avg       0.87      0.86      0.86     82600\n",
      "\n",
      "accuracy_score 0.8568280871670703\n",
      "balanced_accuracy_score 0.7937650882006221\n",
      "average_precision_score 0.456915482655446\n",
      "f1_score 0.6322989863814439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     67995\n",
      "           1       0.58      0.70      0.63     14605\n",
      "\n",
      "    accuracy                           0.86     82600\n",
      "   macro avg       0.76      0.79      0.77     82600\n",
      "weighted avg       0.87      0.86      0.86     82600\n",
      "\n",
      "accuracy_score 0.8554358353510896\n",
      "balanced_accuracy_score 0.7903388263414963\n",
      "average_precision_score 0.4522428667597848\n",
      "f1_score 0.6278323203989403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     67995\n",
      "           1       0.58      0.69      0.63     14605\n",
      "\n",
      "    accuracy                           0.86     82600\n",
      "   macro avg       0.75      0.79      0.77     82600\n",
      "weighted avg       0.87      0.86      0.86     82600\n",
      "\n",
      "accuracy_score 0.8665496368038741\n",
      "balanced_accuracy_score 0.7942130161966166\n",
      "average_precision_score 0.4720738508736721\n",
      "f1_score 0.6438794301037055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     67995\n",
      "           1       0.61      0.68      0.64     14605\n",
      "\n",
      "    accuracy                           0.87     82600\n",
      "   macro avg       0.77      0.79      0.78     82600\n",
      "weighted avg       0.87      0.87      0.87     82600\n",
      "\n",
      "accuracy_score 0.855313018317413\n",
      "balanced_accuracy_score 0.7922709437224196\n",
      "average_precision_score 0.45358857591454727\n",
      "f1_score 0.629345904537419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     67995\n",
      "           1       0.58      0.69      0.63     14604\n",
      "\n",
      "    accuracy                           0.86     82599\n",
      "   macro avg       0.75      0.79      0.77     82599\n",
      "weighted avg       0.87      0.86      0.86     82599\n",
      "\n",
      "accuracy_score 0.8558941391542271\n",
      "balanced_accuracy_score 0.797284014336525\n",
      "average_precision_score 0.45839891676187366\n",
      "f1_score 0.6342377777094921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     67994\n",
      "           1       0.58      0.71      0.63     14605\n",
      "\n",
      "    accuracy                           0.86     82599\n",
      "   macro avg       0.75      0.80      0.77     82599\n",
      "weighted avg       0.87      0.86      0.86     82599\n",
      "\n",
      "accuracy_score 0.8583639027106865\n",
      "balanced_accuracy_score 0.7939455197111105\n",
      "average_precision_score 0.4592610980407177\n",
      "f1_score 0.6341661715500798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     67994\n",
      "           1       0.58      0.69      0.63     14605\n",
      "\n",
      "    accuracy                           0.86     82599\n",
      "   macro avg       0.76      0.79      0.77     82599\n",
      "weighted avg       0.87      0.86      0.86     82599\n",
      "\n",
      "accuracy_score 0.8603615055872347\n",
      "balanced_accuracy_score 0.7881966154514086\n",
      "average_precision_score 0.4577061404491475\n",
      "f1_score 0.6314544989775052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91     67994\n",
      "           1       0.59      0.68      0.63     14605\n",
      "\n",
      "    accuracy                           0.86     82599\n",
      "   macro avg       0.76      0.79      0.77     82599\n",
      "weighted avg       0.87      0.86      0.86     82599\n",
      "\n",
      "Mean F1: 0.6322785648979459 Std F1: 0.004413777375963075\n",
      "Wall time: 37min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_scores = []  # to store the f1_scores for each fold\n",
    "{'sample_size': 300000, 'chi2_features': 30000, 'clf__n_estimators': 50, 'clf__criterion': 'entropy', 'clf__max_depth': 50, \n",
    "                                         'clf__min_samples_split': 100, 'clf__min_samples_leaf': 50, 'clf__class_weight': None, 'clf__bootstrap': False}\n",
    "for train_index, val_index in skf.split(cv_df['Consumer complaint narrative'], cv_df['debt_collection']):\n",
    "    # Tree Params:\n",
    "    sample_size = 300000\n",
    "    chi2_features = 30000\n",
    "    criterion='entropy'\n",
    "    max_depth=60\n",
    "    min_samples_split=50\n",
    "    min_samples_leaf=50\n",
    "    class_weight=None\n",
    "    \n",
    "    \n",
    "    # split the data\n",
    "    X_train_fold, X_val_fold = cv_df['Consumer complaint narrative'][train_index], cv_df['Consumer complaint narrative'][val_index]\n",
    "    y_train_fold, y_val_fold = cv_df['debt_collection'][train_index], cv_df['debt_collection'][val_index]\n",
    "    \n",
    "    # Further Sampling Since we don't need all that\n",
    "    X_train_fold_sample = X_train_fold.sample(sample_size)\n",
    "    y_train_fold_sample = y_train_fold.loc[X_train_fold_sample.index]  # Get the corresponding labels\n",
    "    \n",
    "    # Vectorize the training and validation sets\n",
    "    X_train_fold_sample = loaded_vectorizer.transform(X_train_fold_sample)\n",
    "    X_val_fold = loaded_vectorizer.transform(X_val_fold)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(chi2, k=chi2_features)\n",
    "    X_train_fold_sample = selector.fit_transform(X_train_fold_sample, y_train_fold_sample)\n",
    "    X_val_fold = selector.transform(X_val_fold)\n",
    "    \n",
    "    # Oversampling\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_train_fold_sample, y_train_fold_sample = oversample.fit_resample(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Shuffle your data\n",
    "    X_train_fold_sample, y_train_fold_sample = shuffle(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Define the classifier:\n",
    "    clf = DecisionTreeClassifier(\n",
    "                    criterion=criterion, \n",
    "                    max_depth=max_depth, \n",
    "                    min_samples_split=min_samples_split, \n",
    "                    min_samples_leaf=min_samples_leaf, \n",
    "                    class_weight=class_weight,\n",
    "                    random_state=42\n",
    "                )\n",
    "    clf.fit(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = clf.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate the f1_score and append to the list of f1_scores\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(\"accuracy_score\",accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"balanced_accuracy_score\",balanced_accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"average_precision_score\",average_precision_score(y_val_fold, y_val_pred))\n",
    "    print(\"f1_score\",f1)\n",
    "    print(classification_report(y_val_fold, y_val_pred))\n",
    "    \n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "print('Mean F1:', mean_f1, 'Std F1:', std_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731ae12",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a90b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.884818401937046\n",
      "balanced_accuracy_score 0.8250672267094574\n",
      "average_precision_score 0.5279367807836642\n",
      "f1_score 0.692242996700524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     67995\n",
      "           1       0.66      0.73      0.69     14605\n",
      "\n",
      "    accuracy                           0.88     82600\n",
      "   macro avg       0.80      0.83      0.81     82600\n",
      "weighted avg       0.89      0.88      0.89     82600\n",
      "\n",
      "accuracy_score 0.879225181598063\n",
      "balanced_accuracy_score 0.8256214793569185\n",
      "average_precision_score 0.517571829554726\n",
      "f1_score 0.685001578781181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     67995\n",
      "           1       0.64      0.74      0.69     14605\n",
      "\n",
      "    accuracy                           0.88     82600\n",
      "   macro avg       0.79      0.83      0.81     82600\n",
      "weighted avg       0.89      0.88      0.88     82600\n",
      "\n",
      "accuracy_score 0.8872154963680388\n",
      "balanced_accuracy_score 0.826657622966467\n",
      "average_precision_score 0.5339361817972839\n",
      "f1_score 0.6968040096335351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     67995\n",
      "           1       0.66      0.73      0.70     14605\n",
      "\n",
      "    accuracy                           0.89     82600\n",
      "   macro avg       0.80      0.83      0.81     82600\n",
      "weighted avg       0.89      0.89      0.89     82600\n",
      "\n",
      "accuracy_score 0.8855326876513318\n",
      "balanced_accuracy_score 0.8239957254645387\n",
      "average_precision_score 0.5286366590471353\n",
      "f1_score 0.6924503138925934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     67995\n",
      "           1       0.66      0.73      0.69     14605\n",
      "\n",
      "    accuracy                           0.89     82600\n",
      "   macro avg       0.80      0.82      0.81     82600\n",
      "weighted avg       0.89      0.89      0.89     82600\n",
      "\n",
      "accuracy_score 0.8809322033898305\n",
      "balanced_accuracy_score 0.8251798449948453\n",
      "average_precision_score 0.5204383592251778\n",
      "f1_score 0.6869728508227506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     67995\n",
      "           1       0.64      0.74      0.69     14605\n",
      "\n",
      "    accuracy                           0.88     82600\n",
      "   macro avg       0.79      0.83      0.81     82600\n",
      "weighted avg       0.89      0.88      0.88     82600\n",
      "\n",
      "accuracy_score 0.8874697336561743\n",
      "balanced_accuracy_score 0.8309786583125474\n",
      "average_precision_score 0.5374346128187703\n",
      "f1_score 0.7003063034015798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     67995\n",
      "           1       0.66      0.74      0.70     14605\n",
      "\n",
      "    accuracy                           0.89     82600\n",
      "   macro avg       0.80      0.83      0.82     82600\n",
      "weighted avg       0.89      0.89      0.89     82600\n",
      "\n",
      "accuracy_score 0.8850107144154288\n",
      "balanced_accuracy_score 0.8307944243809797\n",
      "average_precision_score 0.5323219274532852\n",
      "f1_score 0.6966851887334738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     67995\n",
      "           1       0.65      0.75      0.70     14604\n",
      "\n",
      "    accuracy                           0.89     82599\n",
      "   macro avg       0.80      0.83      0.81     82599\n",
      "weighted avg       0.89      0.89      0.89     82599\n",
      "\n",
      "accuracy_score 0.8824198840179663\n",
      "balanced_accuracy_score 0.8274008670861941\n",
      "average_precision_score 0.5248749330298592\n",
      "f1_score 0.6906415238580621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     67994\n",
      "           1       0.65      0.74      0.69     14605\n",
      "\n",
      "    accuracy                           0.88     82599\n",
      "   macro avg       0.79      0.83      0.81     82599\n",
      "weighted avg       0.89      0.88      0.89     82599\n",
      "\n",
      "accuracy_score 0.885640261988644\n",
      "balanced_accuracy_score 0.8275289962804278\n",
      "average_precision_score 0.5313152790660003\n",
      "f1_score 0.6952116675271038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     67994\n",
      "           1       0.66      0.74      0.70     14605\n",
      "\n",
      "    accuracy                           0.89     82599\n",
      "   macro avg       0.80      0.83      0.81     82599\n",
      "weighted avg       0.89      0.89      0.89     82599\n",
      "\n",
      "accuracy_score 0.8835094855869926\n",
      "balanced_accuracy_score 0.8261272393922185\n",
      "average_precision_score 0.5260863351279716\n",
      "f1_score 0.691206675224647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     67994\n",
      "           1       0.65      0.74      0.69     14605\n",
      "\n",
      "    accuracy                           0.88     82599\n",
      "   macro avg       0.80      0.83      0.81     82599\n",
      "weighted avg       0.89      0.88      0.89     82599\n",
      "\n",
      "Mean F1: 0.6927523108575452 Std F1: 0.004423415538917678\n",
      "Wall time: 13min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_scores = []  # to store the f1_scores for each fold\n",
    "\n",
    "for train_index, val_index in skf.split(cv_df['Consumer complaint narrative'], cv_df['debt_collection']):\n",
    "    # RF Params\n",
    "    sample_size = 300000\n",
    "    chi2_features = 30000\n",
    "    n_estimators = 50\n",
    "    criterion ='entropy'\n",
    "    max_depth = 50\n",
    "    min_samples_split = 100\n",
    "    min_samples_leaf = 50\n",
    "    class_weight = None\n",
    "    bootstrap = False\n",
    "    \n",
    "    \n",
    "    # split the data\n",
    "    X_train_fold, X_val_fold = cv_df['Consumer complaint narrative'][train_index], cv_df['Consumer complaint narrative'][val_index]\n",
    "    y_train_fold, y_val_fold = cv_df['debt_collection'][train_index], cv_df['debt_collection'][val_index]\n",
    "    \n",
    "    # Further Sampling Since we don't need all that\n",
    "    X_train_fold_sample = X_train_fold.sample(sample_size)\n",
    "    y_train_fold_sample = y_train_fold.loc[X_train_fold_sample.index]  # Get the corresponding labels\n",
    "    \n",
    "    # Vectorize the training and validation sets\n",
    "    X_train_fold_sample = loaded_vectorizer.transform(X_train_fold_sample)\n",
    "    X_val_fold = loaded_vectorizer.transform(X_val_fold)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(chi2, k=chi2_features)\n",
    "    X_train_fold_sample = selector.fit_transform(X_train_fold_sample, y_train_fold_sample)\n",
    "    X_val_fold = selector.transform(X_val_fold)\n",
    "    \n",
    "    # Oversampling\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_train_fold_sample, y_train_fold_sample = oversample.fit_resample(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Shuffle your data\n",
    "    X_train_fold_sample, y_train_fold_sample = shuffle(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Define the classifier:\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        criterion=criterion, \n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split, \n",
    "        min_samples_leaf=min_samples_leaf, \n",
    "        class_weight=class_weight,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=42,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    clf.fit(X_train_fold_sample, y_train_fold_sample)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_val_pred = clf.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate the f1_score and append to the list of f1_scores\n",
    "    f1 = f1_score(y_val_fold, y_val_pred)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    print(\"accuracy_score\",accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"balanced_accuracy_score\",balanced_accuracy_score(y_val_fold, y_val_pred))\n",
    "    print(\"average_precision_score\",average_precision_score(y_val_fold, y_val_pred))\n",
    "    print(\"f1_score\",f1)\n",
    "    print(classification_report(y_val_fold, y_val_pred))\n",
    "    \n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "print('Mean F1:', mean_f1, 'Std F1:', std_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14105a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
